{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b48ef8e6",
   "metadata": {},
   "source": [
    "# Exemplos Aplicados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6282b851",
   "metadata": {},
   "source": [
    "Nesta seção final, abordaremos alguns exemplos aplicados com o NumPy. Abordaremos alguns exemplos \"do zero\", além de usar a biblioteca scikit-learn. Esperamos que isso convença você da ideia de que usar matrizes e matemática vetorizada pode ser útil e prático."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781fd1c2-0e8b-457d-91f6-7ca5bdc13306",
   "metadata": {},
   "source": [
    "## Regressão Linear com Hill Climbing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add45a8a",
   "metadata": {},
   "source": [
    "Embora este não seja o algoritmo mais eficiente disponível para regressão linear, é um exercício interessante que ensina conceitos aplicáveis ​​a outros problemas. Mais especificamente, vamos aprender a escalar colinas. A ideia por trás da escalar colinas é fazer ajustes aleatórios em uma solução e, se esses ajustes resultarem em uma melhoria, nós os mantemos. Fazemos isso milhares ou milhões de vezes até que a solução não melhore mais.\n",
    "\n",
    "Uma regressão linear simples resolve os coeficientes $ \\beta_0 $ e $ \\beta_1 $, dados os dados de entrada $ x $ e os dados de saída $ y $. Tentamos avaliar uma relação linear entre $ x $ e $ y $ e ajustar os dados de acordo.\n",
    "\n",
    "$$\n",
    "\\Large y = \\Large \\beta_0 + \\Large \\beta_1 x\n",
    "$$\n",
    "\n",
    "Vamos importar essas duas colunas de dados $ x $ e $ y $ do GitHub e salvá-las em dois arrays NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a78f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"https://bit.ly/2KF29Bd\").values\n",
    "x = data[:,0]\n",
    "y = data[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701f90ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792a752d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b40d3ac",
   "metadata": {},
   "source": [
    "Em seguida, declararemos os coeficientes beta `b` como um array NumPy que inicializará $ \\beta_0 $ e $ \\beta_1 $ como $ 0,0 $. Também executaremos nossa escalada de colina por 150.000 iterações (`épocas`) e iniciaremos nossa perda com um número MUITO alto. Isso fará mais sentido em breve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bec92f-fbcb-4dd1-a667-ec97144c40c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construindo o modelo\n",
    "b = np.array([0.0, 0.0]) \n",
    "\n",
    "epocas = 150000  # Número de iterações a serem realizadas\n",
    "n = float(data.shape[0])  # Número de pontos\n",
    "melhor_perda = 10000000000000.0  # Inicializar com um valor bem grande"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d37a2b",
   "metadata": {},
   "source": [
    "Vamos definir como objetivo uma função de perda, mais especificamente a soma dos quadrados. Para uma determinada reta com $ \\beta_0 $ e $ \\beta_1 $, calculamos as diferenças entre a reta e os pontos de dados fornecidos e, em seguida, elevamos ao quadrado e somamos essas diferenças. Essa soma dos quadrados é o que queremos minimizar. Para cada ajuste aleatório em $ \\beta_0 $ e $ \\beta_1 $, calcularemos a soma dos quadrados e verificaremos se ela foi reduzida. Caso contrário, desfazemos esses ajustes aleatórios.\n",
    "\n",
    "Mas como ajustamos aleatoriamente $ \\beta_0 $ e $ \\beta_1 $? Podemos usar valores aleatórios da distribuição normal, com média 0 e desvio padrão 1. Isso criará um volume de ajustes, em sua maioria pequenos, próximos de 0, mas ocasionalmente fazemos ajustes maiores nas extremidades, nas direções positiva e negativa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b450db4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(epocas):\n",
    "\n",
    "    # Ajustar aleatoriamente \"m\" e \"b\"\n",
    "    ajuste_aleatorio = np.random.normal(loc=0, scale=1, size=2)\n",
    "    b += ajuste_aleatorio\n",
    "    \n",
    "    # Calcular a perda (loss), que é o total do erro quadrático somado\n",
    "    nova_perda = ((y - (b[0] + b[1] * x)) ** 2).sum()\n",
    "    \n",
    "    # Se a perda melhorou, manter os novos valores. Caso contrário, reverter.\n",
    "    if nova_perda < melhor_perda:\n",
    "        print(f\"y = {b[0]} + {b[1]}x\")\n",
    "        melhor_perda = nova_perda\n",
    "    else:\n",
    "        b -= ajuste_aleatorio\n",
    "        \n",
    "print(f\"y = {b[0]} + {b[1]}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b2aa34",
   "metadata": {},
   "source": [
    "Para ver rapidamente a qualidade do ajuste, vamos usar o matplotlib para ver o quão bem a linha se ajusta aos pontos de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca3accf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "\n",
    "# show in chart\n",
    "plt.plot(x, y, 'o') # scatterplot\n",
    "plt.plot(x, b[1]*x + b[0]) # line\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f05b052-7fc3-4578-841e-d4a1cb799566",
   "metadata": {},
   "source": [
    "## Regressão Linear com scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8843685c",
   "metadata": {},
   "source": [
    "Embora a escalada possa ser usada para resolver uma variedade de problemas, a regressão linear possui alguns atalhos usando métodos de álgebra linear que abordamos [em outro curso](https://learning.anaconda.cloud/linear-algebra). Mas, por enquanto, podemos usar o scikit-learn e aproveitar matrizes NumPy para passar os dados.\n",
    "\n",
    "Abaixo, lemos o mesmo CSV do exemplo anterior e extraímos as colunas `X` e `y`. Em seguida, ajustamos uma `LinearRegression` e obtemos os coeficientes de `coef_` e `intercept_`. No entanto, eles retornarão matrizes multidimensionais, então as achatamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb0e9d2-947c-499e-b2a2-eb045ec6021e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"https://bit.ly/2KF29Bd\", delimiter=\",\")\n",
    "\n",
    "# Extrair as variáveis de entrada (todas as linhas, todas as colunas exceto a última)\n",
    "x = df.values[:, :-1]\n",
    "\n",
    "# Extrair a variável de saída (todas as linhas, última coluna)\n",
    "y = df.values[:, -1]\n",
    "\n",
    "# Ajustar uma linha aos pontos\n",
    "ajuste = LinearRegression().fit(x, y)\n",
    "\n",
    "# m = 1.7867224, b = -16.51923513\n",
    "b1 = ajuste.coef_.flatten()\n",
    "b0 = ajuste.intercept_.flatten()\n",
    "print(f\"b1 = {b1}\")\n",
    "print(f\"b0 = {b0}\")\n",
    "\n",
    "# Mostrar no gráfico\n",
    "plt.plot(x, y, 'o')  # gráfico de dispersão\n",
    "plt.plot(x, b1*x+b0)  # linha de regressão\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a6dadc-0fd1-4e66-abb8-c6a2ad30c998",
   "metadata": {},
   "source": [
    "## Simulação de fila de clientes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b64d96",
   "metadata": {},
   "source": [
    "Neste exemplo, simularemos clientes entrando em um banco, supermercado, etc., onde serão atendidos individualmente. Para simplificar, teremos apenas um atendente para atender a cada cliente, embora você possa adaptar isso para atender a vários atendentes. O objetivo desta simulação é verificar se uma fila se formará e ficará fora de controle, e teoricamente poderíamos usar isso para prever o tempo médio de espera dos clientes.\n",
    "\n",
    "Lembre-se de que estudamos diversas distribuições de probabilidade. A distribuição normal pode fazer sentido para o tempo de atendimento ao cliente, assumindo que o tempo de atendimento segue uma distribuição normal. Mas e quanto ao fluxo de clientes na loja? A distribuição exponencial modelará o tempo decorrido entre a entrada de cada cliente.\n",
    "\n",
    "Vamos construir a simulação abaixo usando a distribuição normal e a distribuição exponencial. Os clientes levarão em média 3 minutos para serem atendidos, com um desvio padrão de 0,5 minuto. Modelaremos 20 clientes, em média, chegando a cada hora, mas para sermos consistentes em minutos, isso equivale a US$ 1/3 de um cliente a cada minuto. Executaremos a simulação para os primeiros 100 clientes.\n",
    "\n",
    "Observe que isso é um pouco complexo, mas a ideia é usar essas duas distribuições para criar uma simulação \"realista\". Execute a simulação e observe o resultado antes de mergulhar no código em si."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec202e88-da12-4a5b-8dcf-d089e139d035",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import normal, exponential\n",
    "\n",
    "np.random.seed(0)  # Usar semente aleatória para executar simulações \"aleatórias\" idênticas\n",
    "\n",
    "tempo_medio_caixa = 3  # minutos\n",
    "desvio_padrao_caixa = 0.5  # minutos\n",
    "taxa_media_chegada = 20 / 60  # clientes por minuto\n",
    "qtd_clientes = 100\n",
    "\n",
    "# Tempos entre chegadas dos clientes (tempo entre cada cliente em relação ao anterior)\n",
    "tempos_entre_clientes = exponential(scale=1/taxa_media_chegada, size=qtd_clientes+2)  # precisa adicionar 2 para evitar erro de índice\n",
    "\n",
    "# Horário de chegada de cada cliente (minutos desde o início da simulação)\n",
    "horarios_chegada_clientes = np.cumsum(tempos_entre_clientes)\n",
    "\n",
    "# Tempos de atendimento dos clientes\n",
    "tempos_atendimento_clientes = normal(loc=tempo_medio_caixa, scale=desvio_padrao_caixa, size=qtd_clientes+2)  # adicionar 2 para evitar erro de índice\n",
    "\n",
    "# Começar o tempo no 0, mas pular para a chegada do primeiro cliente\n",
    "# e rastrear se há cliente sendo atendido e quais estão esperando\n",
    "tempo_atual = horarios_chegada_clientes[0]\n",
    "clientes_esperando = []\n",
    "\n",
    "cliente_chegou_i = 0\n",
    "cliente_sendo_processado_i = 0\n",
    "inicio_atendimento_cliente = horarios_chegada_clientes[0]\n",
    "\n",
    "# Processar clientes até que todos tenham chegado\n",
    "while cliente_chegou_i < qtd_clientes:\n",
    "\n",
    "    # Horário de chegada do cliente sendo atendido\n",
    "    chegada_cliente_processando = horarios_chegada_clientes[cliente_sendo_processado_i]\n",
    "\n",
    "    # Horário programado de término do atendimento do cliente\n",
    "    fim_cliente_processando = inicio_atendimento_cliente + \\\n",
    "                              tempos_atendimento_clientes[cliente_sendo_processado_i]\n",
    "\n",
    "    # Próxima chegada de cliente\n",
    "    def proxima_chegada_cliente(): return horarios_chegada_clientes[cliente_chegou_i+1]\n",
    "\n",
    "    # VERIFICAR QUAL EVENTO OCORREU COMPARANDO OS TEMPOS\n",
    "    proximo_evento = None\n",
    "\n",
    "    # Se for o primeiro cliente\n",
    "    if tempo_atual == inicio_atendimento_cliente:\n",
    "        print(f\"{tempo_atual}: CLIENTE {cliente_chegou_i} CHEGOU, SEM FILA, ATENDIMENTO IMEDIATO\")\n",
    "        proximo_evento = np.min([fim_cliente_processando, proxima_chegada_cliente()])\n",
    "\n",
    "    # Se um cliente chegar\n",
    "    elif tempo_atual == proxima_chegada_cliente():\n",
    "        cliente_chegou_i += 1  # Incrementa o índice de clientes que chegaram\n",
    "\n",
    "        # Se não houver fila e o cliente que chegou for o próximo a ser atendido\n",
    "        if cliente_sendo_processado_i == cliente_chegou_i:\n",
    "            inicio_atendimento_cliente = tempo_atual\n",
    "            fim_cliente_processando = inicio_atendimento_cliente + tempos_atendimento_clientes[cliente_sendo_processado_i]\n",
    "\n",
    "            print(f\"{tempo_atual}: CLIENTE {cliente_chegou_i} CHEGOU, SEM FILA, ATENDIMENTO IMEDIATO\")\n",
    "        else:\n",
    "            # Senão, há fila e o cliente precisa esperar\n",
    "            clientes_esperando.append(cliente_chegou_i)\n",
    "            print(f\"{tempo_atual}: CLIENTE {cliente_chegou_i} CHEGOU, ADICIONANDO À FILA {clientes_esperando}\")\n",
    "\n",
    "        # Próximo evento: cliente atual terminando ou próximo cliente chegando\n",
    "        proximo_evento = np.min([fim_cliente_processando, proxima_chegada_cliente()])\n",
    "\n",
    "    # Se um cliente terminar o atendimento\n",
    "    elif tempo_atual == fim_cliente_processando:\n",
    "\n",
    "        # Se a fila não estiver vazia, atender o próximo da fila\n",
    "        if clientes_esperando:\n",
    "            clientes_esperando.pop(0)\n",
    "            print(f\"{tempo_atual}: CLIENTE {cliente_sendo_processado_i} TERMINOU, CLIENTE {cliente_sendo_processado_i + 1}\"\n",
    "                  f\" REMOVIDO DA FILA {clientes_esperando}\")\n",
    "\n",
    "            inicio_atendimento_cliente = tempo_atual\n",
    "\n",
    "            # Próximo evento: este cliente terminando ou próximo cliente chegando\n",
    "            proximo_evento = np.min([\n",
    "                inicio_atendimento_cliente + tempos_atendimento_clientes[cliente_sendo_processado_i + 1],\n",
    "                proxima_chegada_cliente()\n",
    "            ])\n",
    "        else:\n",
    "            # Se a fila estiver vazia, esperar o próximo cliente\n",
    "            print(f\"{tempo_atual}: CLIENTE {cliente_sendo_processado_i} TERMINOU, ESPERANDO O CLIENTE {cliente_sendo_processado_i + 1}\")\n",
    "            proximo_evento = proxima_chegada_cliente()\n",
    "\n",
    "        cliente_sendo_processado_i += 1  # Próximo cliente a ser processado\n",
    "\n",
    "    # Avançar para o próximo evento\n",
    "    tempo_atual = proximo_evento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfae52a9",
   "metadata": {},
   "source": [
    "Ao executar a simulação acima, você verá que uma fila se forma irremediavelmente após um tempo suficiente. Isso deve indicar que outro caixa pode ser necessário para atender os clientes! Você também pode experimentar tempos de atendimento mais curtos ou intervalos maiores entre os clientes, e descobrirá que há um equilíbrio ideal em algum momento em que o atendimento acompanha a fila."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3341f7ff-1658-4a3d-bc63-aaba1052daa5",
   "metadata": {},
   "source": [
    "## Rede Neural com scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c61221b",
   "metadata": {},
   "source": [
    "Vamos dar uma olhada em um último exemplo de uso do NumPy com o scikit-learn. Vamos primeiro importar algumas informações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1397085e-d4b4-40ab-8f70-68700fb9add7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0f6402",
   "metadata": {},
   "source": [
    "Vamos introduzir o conjunto de dados MNIST. Observe que cada linha é uma imagem de um dígito escrito à mão, embora isso ainda não seja totalmente óbvio. Mas vemos que cada coluna contém um valor de pixel para cada imagem/linha. A única exceção é a última coluna, que é o rótulo do dígito que a imagem representa, entre 0 e 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2a3ea4-02d5-4e35-9fb6-b318b5cf4339",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://bit.ly/3ilJc2C', compression='zip', delimiter=\",\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d2a6a2",
   "metadata": {},
   "source": [
    "Esses valores de pixel representam o quão escuro ele está, em uma escala entre 0 e 255. Vamos dividir por 255 para que fique entre 0 e 1. Vamos também pegar as colunas de entrada de pixels como `x` e a coluna de saída dos rótulos `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0592d7b-021e-4881-8506-e321f602b6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.values[:, :-1] / 255.0\n",
    "y = df.values[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f55c28a",
   "metadata": {},
   "source": [
    "Em aprendizado de máquina, é uma boa prática reservar parte dos dados como conjunto de dados de teste (por exemplo, 1/3 dos dados) e usar os dados restantes como conjunto de dados de treinamento (por exemplo, 2/3). Dessa forma, podemos usar os dados de teste posteriormente para avaliar o desempenho do modelo em dados que ele ainda não viu. O método `train_test_split()` fará isso por nós e retornará quatro matrizes NumPy que servirão como conjuntos de dados de treinamento/teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c111f8-5007-4bb9-9391-e2aa7245bd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar dados de treino e teste\n",
    "# cada classe é proporcionalmente representada em ambos os conjuntos\n",
    "X_treino, X_teste, Y_treino, Y_teste = train_test_split(x, y,\n",
    "    test_size=1/3, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958b08c0",
   "metadata": {},
   "source": [
    "Por fim, criaremos uma rede neural de classificação `MLPClassifier` a partir do scikit-learn. Passaremos os dados `X_train` e `Y_train` para o modelo, usaremos 100 nós ocultos em uma única camada oculta e usaremos uma função de ativação logística para a camada oculta. Se você não está familiarizado com aprendizado de máquina ou redes neurais, [há uma aula no Anaconda que ensina esse tópico](https://learning.anaconda.cloud/getting-started-with-ai-ml).\n",
    "\n",
    "Vamos treinar o modelo e, em seguida, avaliar a precisão dos dados de teste. Podemos ir um passo além e criar uma matriz de confusão, que rastreia com que frequência cada dígito foi identificado corretamente e, quando não foram, quais dígitos foram classificados incorretamente. A própria matriz de confusão será retornada como um array NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c55b57-fcd9-47b7-97b1-31ee66ab7b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = MLPClassifier(solver='sgd',\n",
    "                   hidden_layer_sizes=(100, ),\n",
    "                   activation='logistic',\n",
    "                   max_iter=480,\n",
    "                   learning_rate_init=.1)\n",
    "\n",
    "nn.fit(X_treino, Y_treino)\n",
    "\n",
    "print(f\"Acurácia no conjunto de teste: {nn.score(X_teste, Y_teste)}\")\n",
    "\n",
    "matriz_confusao = confusion_matrix(y_true=Y_teste, y_pred=nn.predict(X_teste))\n",
    "print(matriz_confusao)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707a5307",
   "metadata": {},
   "source": [
    "Isso deve nos dar muitos exemplos para refletir. Espero que você perceba que o NumPy é um bloco de construção para executar muitas tarefas e trabalhar com muitas bibliotecas, como o scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be2ea66",
   "metadata": {},
   "source": [
    "## Exercício"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c59c381",
   "metadata": {},
   "source": [
    "Complete o código abaixo para realizar uma regressão linear neste conjunto de dados no GitHub. A coluna da esquerda é a variável de entrada `x` e a coluna da direita é a variável de saída `y`.\n",
    "\n",
    "Complete substituindo os pontos de interrogação `?` abaixo, incluindo a extração dos coeficientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265a126a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "url = r\"https://raw.githubusercontent.com/thomasnield/machine-learning-demo-data/master/regression/linear_normal.csv\"\n",
    "df = pd.read_csv(url, delimiter=\",\")\n",
    "\n",
    "# Extrair variáveis de entrada (todas as linhas, todas as colunas exceto a última)\n",
    "x = ?\n",
    "\n",
    "# Extrair a coluna de saída (todas as linhas, última coluna)\n",
    "y = ?\n",
    "\n",
    "# Ajustar uma linha aos pontos\n",
    "ajuste = LinearRegression().fit(?, ?)\n",
    "\n",
    "b1 = ajuste.coef_.?\n",
    "b0 = ajuste.intercept_.?\n",
    "print(f\"b1 = {b1}\")\n",
    "print(f\"b0 = {b0}\")\n",
    "\n",
    "# Mostrar no gráfico\n",
    "plt.plot(x, y, 'o')  # gráfico de dispersão\n",
    "plt.plot(x, b1*x+b0)  # linha de regressão\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0812529",
   "metadata": {},
   "source": [
    "### RESPOSTA A BAIXO\n",
    "\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "v "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c4d306",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "url = r\"https://raw.githubusercontent.com/thomasnield/machine-learning-demo-data/master/regression/linear_normal.csv\"\n",
    "df = pd.read_csv(url, delimiter=\",\")\n",
    "\n",
    "# Extrair variáveis de entrada (todas as linhas, todas as colunas exceto a última)\n",
    "x = df.values[:, :-1]\n",
    "\n",
    "# Extrair variável de saída (todas as linhas, última coluna)\n",
    "y = df.values[:, -1]\n",
    "\n",
    "# Ajustar uma linha aos pontos\n",
    "ajuste = LinearRegression().fit(x, y)\n",
    "\n",
    "b1 = ajuste.coef_.flatten()\n",
    "b0 = ajuste.intercept_.flatten()\n",
    "print(f\"b1 = {b1}\")\n",
    "print(f\"b0 = {b0}\")\n",
    "\n",
    "# Mostrar no gráfico\n",
    "plt.plot(x, y, 'o')  # Gráfico de dispersão\n",
    "plt.plot(x, b1 * x + b0)  # Linha de regressão\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba2ece7-ca60-4a4c-9c94-b6f493b1a208",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-2024.02-py310",
   "language": "python",
   "name": "conda-env-anaconda-2024.02-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
