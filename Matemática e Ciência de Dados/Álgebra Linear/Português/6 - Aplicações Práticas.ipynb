{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59ffd5a6",
   "metadata": {},
   "source": [
    "# Aplicações Práticas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27f3681",
   "metadata": {},
   "source": [
    "Aprendemos álgebra linear o suficiente para sermos perigosos e nos acostumarmos com o uso de bibliotecas de aprendizado de máquina e ciência de dados. No entanto, vamos dar um passo adiante e usar a álgebra linear para resolver alguns problemas \"do zero\", usando apenas o NumPy. Ao resolver esses problemas, você verá como a álgebra linear é usada na prática e terá uma visão mais aprofundada de como bibliotecas e técnicas funcionam.\n",
    "\n",
    "Vamos começar resolvendo um sistema de equações."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13733d9",
   "metadata": {},
   "source": [
    "## Sistemas de equações"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b71af6",
   "metadata": {},
   "source": [
    "Vamos dar um uso às matrizes inversas. Digamos que você tenha um sistema de equações lineares como o mostrado abaixo e precise resolver para $ x $, $ y $ e $ z $.\n",
    "\n",
    "$\n",
    "2x + 9y - 3z = 12 \\\\\n",
    "x + 2y + 7z = 5 \\\\\n",
    "x + 2y + 3z = 6\n",
    "$\n",
    "\n",
    "Você poderia tentar resolver isso algebricamente, mas, na verdade, pode usar uma abordagem de álgebra linear. Primeiro, vamos extrair os coeficientes multiplicados em cada variável. Observe que, se não houver coeficiente, o coeficiente é efetivamente $ 1 $, pois multiplicar por $ 1 $ não tem impacto. Além disso, uma subtração em vez de uma adição de um elemento tratará o coeficiente como negativo.\n",
    "\n",
    "\n",
    "$\n",
    "A = \\begin{bmatrix} \n",
    "2 & 9 & -3 \\\\\n",
    "1 & 2 & 7 \\\\\n",
    "1 & 2 & 3 \n",
    "\\end{bmatrix}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df155bd9",
   "metadata": {},
   "source": [
    "Antes de prosseguirmos, vamos garantir que o determinante desta matriz não seja zero. Se for, significa que nosso sistema de equações será insolúvel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fede0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import det\n",
    "from numpy import array \n",
    "\n",
    "A = array([\n",
    "    [2, 9, -3],\n",
    "    [1, 2, 7],\n",
    "    [1, 2, 3]\n",
    "])\n",
    "\n",
    "det(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3b5449",
   "metadata": {},
   "source": [
    "Certo, o determinante é aproximadamente 20, então podemos prosseguir.\n",
    "\n",
    "A seguir, vamos pegar os termos à direita do sinal de igual $ = $ e criar esse vetor como $ B $.\n",
    "\n",
    "$\n",
    "B = \\begin{bmatrix} 12 \\\\ 5 \\\\ 6 \\end{bmatrix}\n",
    "$\n",
    "\n",
    "Agora, vamos considerar um vetor $ X $ que contém todas as três variáveis ​​não resolvidas $ x $, $ y $ e $ z $. \n",
    "\n",
    "$ \n",
    "X = \\begin{bmatrix} x \\\\ y \\\\ z \\end{bmatrix}\n",
    "$\n",
    "\n",
    "Se realizarmos a multiplicação de vetores matriciais entre $ A $ e $ X $, isso resultará no vetor $ B $.\n",
    "\n",
    "$\n",
    "AX = B\n",
    "$\n",
    "\n",
    "$\n",
    "\\begin{bmatrix} \n",
    "2 & 9 & -3 \\\\\n",
    "1 & 2 & 7 \\\\\n",
    "1 & 2 & 3 \n",
    "\\end{bmatrix} \\begin{bmatrix} x \\\\ y \\\\ z \\end{bmatrix} = \\begin{bmatrix} 12 \\\\ 5 \\\\ 6 \\end{bmatrix}\n",
    "$\n",
    "\n",
    "$\n",
    "\\begin{bmatrix} \n",
    "2x + 9y -3z \\\\\n",
    "x + 2y + 7z \\\\\n",
    "x + 2y + 3z \n",
    "\\end{bmatrix} = \\begin{bmatrix} 12 \\\\ 5 \\\\ 6 \\end{bmatrix}\n",
    "$\n",
    "\n",
    "Voltemos a esta expressão:\n",
    "\n",
    "$\n",
    "AX = B\n",
    "$\n",
    "\n",
    "Se \"multiplicarmos\" cada lado pela inversa da matriz $A$, que denotaremos como $ A^{-1} $, podemos isolar efetivamente $ X $.\n",
    "\n",
    "$ \n",
    "A^{-1}AX= A^{-1}B\n",
    "$\n",
    "\n",
    "$ \n",
    "X = A^{-1}B\n",
    "$\n",
    "\n",
    "A razão pela qual $ A^{-1}A $ se cancela é que a multiplicação de suas matrizes resulta em uma matriz identidade, isolando efetivamente $ x $, $ y $ e $ z $. Multiplicar por uma matriz identidade é o equivalente em álgebra linear de multiplicar por $ 1 $. Não tem efeito.\n",
    "\n",
    "$\n",
    "A^{-1}A = \\begin{bmatrix} \n",
    "1 & 0 & 0 \\\\\n",
    "0 & 1 & 0 \\\\\n",
    "0 & 0 & 1 \n",
    "\\end{bmatrix} \n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe8355c",
   "metadata": {},
   "source": [
    "$\n",
    "A^{-1}AX = \\begin{bmatrix} \n",
    "1 & 0 & 0 \\\\\n",
    "0 & 1 & 0 \\\\\n",
    "0 & 0 & 1 \n",
    "\\end{bmatrix} \\begin{bmatrix} x \\\\ y \\\\ z \\end{bmatrix} = \\begin{bmatrix} x \\\\ y \\\\ z \\end{bmatrix}\n",
    "$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b5bff1",
   "metadata": {},
   "source": [
    "Posso provar isso usando o NumPy. Vamos calcular o inverso de $ A $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee39ee5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from numpy.linalg import inv\n",
    "\n",
    "A = array([\n",
    "    [2, 9, -3],\n",
    "    [1, 2, 7],\n",
    "    [1, 2, 3]\n",
    "])\n",
    "\n",
    "A_inv = inv(A)\n",
    "\n",
    "A_inv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ad897a",
   "metadata": {},
   "source": [
    "E vamos aplicar o inverso $ A^{-1} $ a $ A $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bc1e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_inv @ A "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8acb3f8",
   "metadata": {},
   "source": [
    "No entanto, como o NumPy tem algumas complicações com ponto flutuante, como mostrado acima, prefiro usar o SymPy, pois ele me dará uma resposta muito mais limpa, com apenas 1 e 0. Isso porque ele faz matemática simbólica em vez de aritmética de ponto flutuante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed63c573",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sympy import Matrix\n",
    "\n",
    "A = Matrix([\n",
    "    [2, 9, -3],\n",
    "    [1, 2, 7],\n",
    "    [1, 2, 3]\n",
    "])\n",
    "\n",
    "A_inv = A.inv()\n",
    "A_inv @ A "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02103907",
   "metadata": {},
   "source": [
    "Devido a esse raciocínio, podemos calcular o vetor $ X $ contendo $ x $, $ y $ e $ z $ usando o inverso da matriz $ A $ multiplicado pelo vetor $ B $.\n",
    "\n",
    "$\n",
    "X = A^{-1}B\n",
    "$\n",
    "\n",
    "Vamos usar o NumPy para resolver este sistema de equações usando a expressão simples que resolve $ X $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfc349e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from numpy.linalg import inv\n",
    "\n",
    "# 2x + 9y - 3z = 12\n",
    "# 1x + 2y + 7z = 5\n",
    "# 1x + 2y + 3z = 6\n",
    "\n",
    "A = array([\n",
    "    [2, 9, -3],\n",
    "    [1, 2, 7],\n",
    "    [1, 2, 3]\n",
    "])\n",
    "\n",
    "B = array([\n",
    "    12,\n",
    "    5,\n",
    "    6\n",
    "])\n",
    "\n",
    "X = inv(A) @ B \n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00d5aeb",
   "metadata": {},
   "source": [
    "Portanto, encontramos que $ X = \\begin{bmatrix} 7,65 \\\\ -0,45 \\\\ -0,25 \\end{bmatrix} $. Isso significa $ x = 7,65 $, $ y = -0,45 $ e $ z = -0,25 $.\n",
    "\n",
    "Resolver um sistema de equações como este se estende a muitos problemas, como programação linear e muitas áreas da pesquisa científica.\n",
    "\n",
    "Aqui está uma visualização deste sistema de equações sendo resolvido. Observe como o vetor amarelo $ B $ se desloca após os vetores base que refletem a matriz $ A $ serem movidos para suas posições de identidade. Isso resulta no vetor $ B $ se tornando o vetor $ X $, resolvendo efetivamente as variáveis.\n",
    "<br><br>\n",
    "\n",
    "<video src=\"https://github.com/thomasnield/anaconda_linear_algebra/raw/main/media/01_SystemOfEquationsScene.mp4\" controls=\"controls\" style=\"max-width: 730px;\">\n",
    "</video>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182cfc2e",
   "metadata": {},
   "source": [
    "## Decomposição própria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97352c0b",
   "metadata": {},
   "source": [
    "A decomposição matricial consiste em dividir uma matriz em componentes, de forma semelhante à fatoração de números (por exemplo, 6 pode ser fatorado para 2 × 3). Usamos a decomposição matricial para diversas tarefas, como ajustar uma regressão linear (o que faremos após esta seção) e calcular matrizes inversas. Neste exemplo, falaremos sobre um tipo comum de decomposição matricial chamado autodecomposição, frequentemente usada em aprendizado de máquina e análise de componentes principais. Neste nível, não temos espaço para nos aprofundarmos em cada uma dessas aplicações, mas pelo menos aprenderemos o processo para nos familiarizarmos com a decomposição.\n",
    "\n",
    "A fórmula para autodecomposição é a seguinte, onde $ v $ são os autovalores e $ \\lambda $ são os autovetores. $ A $ é a matriz original.\n",
    "\n",
    "$\n",
    "Av = \\lambda v\n",
    "$\n",
    "\n",
    "Há um autovetor e um autovalor para cada dimensão da matriz $ A $, e nem toda matriz pode ser decomposta com autodecomposição.\n",
    "\n",
    "Vamos realizar a autodecomposição na matriz $A$ abaixo usando a função `eig()` no pacote `linalg` do NumPy. Isso resultará nestes dois componentes: autovetores e autovalores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393d941e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array, diag\n",
    "from numpy.linalg import eig, inv \n",
    "\n",
    "\n",
    "A = array([\n",
    "    [2, 9,],\n",
    "    [1, 2,]\n",
    "])\n",
    "\n",
    "\n",
    "eigenvals, eigenvecs = eig(A)\n",
    "\n",
    "print(\"AUTOVALORES\")\n",
    "print(eigenvals)\n",
    "print(\"\\nAUTOVETORES\")\n",
    "print(eigenvecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3c42c5",
   "metadata": {},
   "source": [
    "Agora, como recompomos a matriz $A$ a partir dos autovetores e autovalores? Para reconstruir, precisamos desta fórmula:\n",
    "\n",
    "$\n",
    "A = Q \\Lambda Q^{-1}\n",
    "$\n",
    "\n",
    "$Q$ são os autovetores, $ \\Lambda $ são os autovalores na forma diagonal e $Q^{-1}$ é a matriz inversa de $Q$.\n",
    "\n",
    "Vamos reconstruir isso com NumPy e, com certeza, você verá a matriz original $A$ montada novamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b83b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = eigenvecs\n",
    "Q_inv = inv(Q)\n",
    "\n",
    "L = diag(eigenvals)\n",
    "A = Q @ L @ Q_inv\n",
    "\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a5cc11",
   "metadata": {},
   "source": [
    "## Regressão Linear\n",
    "\n",
    "Aqui está outro caso em que podemos usar a álgebra linear para um problema altamente útil. Uma **regressão linear** ajusta uma reta aos dados observados, tentando demonstrar uma relação linear entre variáveis ​​e fazer previsões sobre novos dados ainda a serem observados. Embora existam muitas maneiras de ajustar uma regressão linear, incluindo gradiente descendente, podemos usar matrizes inversas, bem como técnicas de decomposição de matrizes. Vamos começar com uma técnica de matriz inversa.\n",
    "\n",
    "Vamos primeiro obter um conjunto de dados contendo duas colunas $ x $ e $ y $ do GitHub e salvá-lo em um DataFrame do Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a67b614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "url = r\"https://raw.githubusercontent.com/thomasnield/machine-learning-demo-data/master/regression/linear_normal.csv\"\n",
    "\n",
    "df = pd.read_csv(url, delimiter=\",\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a780625",
   "metadata": {},
   "source": [
    "Em seguida, vamos visualizar esses dados usando matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9aae3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extrair variáveis ​​de entrada (todas as linhas e todas as colunas, exceto a última)\n",
    "X = df.values[:, :-1]\n",
    "\n",
    "# Extrair coluna de saída (todas as linhas, última coluna)\n",
    "Y = df.values[:, -1]\n",
    "plt.plot(X, Y, 'o') # gráfico de dispersão\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d61188",
   "metadata": {},
   "source": [
    "Observando esses dados, parece haver definitivamente uma relação linear, pois quando $ x $ aumenta/diminui proporcionalmente, $ y $ também aumenta/diminui proporcionalmente. Vamos aprender a ajustar uma reta usando algumas técnicas de álgebra linear.\n",
    "\n",
    "Primeiro, vamos observar a seguinte fórmula para obter um vetor de coeficientes $ b $ para uma função linear.\n",
    "\n",
    "$\n",
    "\\Large b = (X^T \\cdot X)^{-1} \\cdot X^T \\cdot y\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b08990",
   "metadata": {},
   "source": [
    "$ X $ é uma matriz dos valores da variável de entrada, que neste caso possui apenas uma coluna. No entanto, vamos preencher alguns 1s como uma coluna extra para que isso gere um coeficiente de interceptação e não apenas uma inclinação. $ y $ é o vetor da variável de saída. $ X^T $ é a matriz transposta de $ X $.\n",
    "\n",
    "Vamos primeiro preencher $ X $ com uma coluna extra de 1s e chamá-la de `X_1`. Usaremos isso no lugar de $ X $ em nossa fórmula acima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7447e1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionar coluna de espaço reservado \"1\" para gerar interceptação\n",
    "X_1 = np.vstack([X.flatten(), np.ones(len(X))]).transpose()\n",
    "\n",
    "X_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8929b713",
   "metadata": {},
   "source": [
    "Agora, vamos aplicar esta fórmula e executá-la usando o NumPy. Agora, obteremos os coeficientes no vetor $b$.\n",
    "\n",
    "$\n",
    "\\Large b = (X^T \\cdot X)^{-1} \\cdot X^T \\cdot y\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3b4298",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = inv(X_1.transpose() @ X_1) @ (X_1.transpose() @ Y)\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735d82dd",
   "metadata": {},
   "source": [
    "$ 1,75919315 $ é o valor da inclinação e $ 4,69359655 $ é o valor da interceptação. Vamos traçar a reta que passa pelos pontos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fc068c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X, Y, 'o') # gráfico de dispersão\n",
    "plt.plot(X, X_1 @ b) # linha\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1c535a",
   "metadata": {},
   "source": [
    "Isso parece correto e, para este problema específico, está correto. No entanto, quando você tem muitos dados com muitas colunas, os computadores podem começar a produzir resultados instáveis ​​devido a problemas de precisão de ponto flutuante. Este é um caso de uso para decomposição matricial, que neste caso podemos usar a decomposição QR. Decompondo primeiro $ X $ nos componentes $ Q $ e $ R $ (e por $ X $ quero dizer com a coluna de 1s), podemos tornar esta regressão linear mais estável numericamente.\n",
    "\n",
    "Podemos primeiro decompor $ X $ nos componentes $ Q $ e $ R $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f863c840",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from numpy.linalg import qr\n",
    "\n",
    "Q,R = qr(X_1)\n",
    "print(\"Q:\")\n",
    "print(Q)\n",
    "\n",
    "print(\"R:\")\n",
    "print(R)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8e83f3",
   "metadata": {},
   "source": [
    "Podemos então usar esta fórmula para calcular os coeficientes no vetor $ b $.\n",
    "\n",
    "$\n",
    "\\Large b = R^{-1} \\cdot Q^T \\cdot y\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e09ca4c",
   "metadata": {},
   "source": [
    "Tudo o que precisamos do NumPy é algum trabalho de matriz inversa e transposição, e depois alguma multiplicação de matrizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf349cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = inv(R) @ Q.transpose() @ Y \n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80744ede",
   "metadata": {},
   "source": [
    "Novamente, 1,75919315 é o valor da inclinação e 4,69359655 é o valor da interceptação. Isso nos dá exatamente a mesma resposta que a técnica inversa simples, mas para conjuntos de dados maiores e mais complexos, essa abordagem de decomposição QR será mais estável numericamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f60f914",
   "metadata": {},
   "source": [
    "## Redes Neurais"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b79e0a",
   "metadata": {},
   "source": [
    "Um caso de uso intensivo para álgebra linear tornou-se redes neurais e aprendizado profundo. Vamos ver como isso funciona para implementar uma rede neural simples de propagação direta completamente do zero usando apenas o NumPy. Não vamos aprender sobre retropropagação e gradiente descendente aqui, leiam o livro [_Matemática Essencial para Ciência de Dados_](https://learning.oreilly.com/library/view/essential-math-for/9781098102920/).\n",
    "\n",
    "Digamos que temos alguns dados representando diferentes cores de fundo (com as variáveis ​​de entrada `RED`, `GREEN` e `BLUE`). Também temos um `LIGHT_OR_DARK_FONT_IND` que indica se uma fonte clara (0) ou escura (1) funcionará melhor com esse fundo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb4122b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"https://tinyurl.com/y2qmhfsr\")\n",
    "df.sample(10, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7e9b55",
   "metadata": {},
   "source": [
    "Vamos capturar as três colunas de entrada como matriz $ X $ e a coluna de saída como vetor $ Y $.\n",
    "\n",
    "$\n",
    "X = \\begin{bmatrix}179 & 204 & 255\\\\179 & 179 & 179\\\\205 & 102 & 29\\\\173 & 216 & 230\\\\122 & 197 & 205\\\\ & ... & \\\\ 0 & 197 & 205\\\\197 & 193 & 170\\\\70 & 130 & 180\\\\205 & 200 & 177\\\\0 & 139 & 69\\end{bmatrix}\n",
    "$\n",
    "\n",
    "$\n",
    "Y = \\begin{bmatrix}1\\\\1\\\\0\\\\1\\\\1\\\\...\\\\1\\\\1\\\\0\\\\1\\\\0\\end{bmatrix}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a911ca",
   "metadata": {},
   "source": [
    "Podemos extrair $ X $ e $ Y $ como matrizes NumPy do `DataFrame`. Também reduziremos $ X $ em 255 para que os valores de entrada fiquem entre 0 e 1. Isso reduzirá o espaço numérico para um intervalo menor e matematicamente mais conveniente do que o intervalo completo de 0 a 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70a7946",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.values[:,:3] / 255 \n",
    "Y = df.values[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3ce798",
   "metadata": {},
   "source": [
    "Normalmente, usaríamos esses dados para treinar uma rede neural para prever uma fonte clara ou escura para uma determinada cor de fundo. No entanto, a rede neural que estamos prestes a construir já está \"treinada\" para fins de escopo nesta aula.\n",
    "\n",
    "Poderíamos usar modelos mais simples, como regressão logística, para este problema, mas este é um ótimo problema de brinquedo para entender redes neurais. É também um microcosmo da visão computacional, já que as três variáveis ​​de entrada `VERMELHO`, `VERDE` e `AZUL` podem representar um único pixel em uma imagem.\n",
    "\n",
    "Vamos fazer um rápido curso intensivo sobre redes neurais com o auxílio de alguma animação. Uma rede neural é uma série de operações de multiplicação e adição em várias camadas (portanto, multiplicação de matrizes) com algumas funções não lineares na mistura. A saída é um valor entre 0 e 1, sugerindo a \"probabilidade\" de uma fonte escura."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29dccfb3",
   "metadata": {},
   "source": [
    "\n",
    "<video src=\"https://github.com/thomasnield/anaconda_linear_algebra/raw/main/media/02_NeuralNetworkScene.mp4\" controls=\"controls\" style=\"max-width: 730px;\">\n",
    "</video>\n",
    "\n",
    "Acima, representamos as entradas `VERMELHO`, `VERDE` e `AZUL` como $x_1$, $x_2$ e $x_3$. Isso representaria uma linha da matriz $ X $. Temos três nós na *camada oculta* e associamos pesos de $w_1$ a $w_9$ para cada par de nós de entrada ao nó oculto. Também adicionamos um valor de viés a cada nó. O valor resultante é passado para uma função não linear chamada ReLU, que simplesmente transforma valores negativos em 0. Repetimos esse processo novamente entre os nós ocultos e o nó de saída, o que envolve outros três pesos de $w_{10}$ a $w_{12}$ e outro valor de viés $b_4$. Este é passado por uma função sigmoide. Se esse valor de saída for menor que $0,5$, o categorizamos como `LIGHT`. Caso contrário, o categorizamos como `DARK`.\n",
    "\n",
    "Observe como cada camada de nós pode ser representada puramente por matrizes de pesos e vieses. Vamos capturá-los abaixo.\n",
    "\n",
    "<br><br>\n",
    "\n",
    "\n",
    "$\n",
    "W_{hidden} = \\begin{bmatrix}\n",
    "w_1 & w_2 & w_3 \\\\\n",
    "w_4 & w_5 & w_6 \\\\\n",
    "w_7 & w_8 & w_9\n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "$\n",
    "W_{output} = \\begin{bmatrix}\n",
    "w_{10} \\\\\n",
    "w_{11} \\\\\n",
    "w_{12} \n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "\n",
    "$\n",
    "B_{hidden} = \\begin{bmatrix}b_1\\\\b_2\\\\b_3 \\end{bmatrix}\n",
    "$\n",
    "\n",
    "$\n",
    "B_{output} = \\begin{bmatrix}b_4\\end{bmatrix}\n",
    "$ \n",
    "\n",
    "<br><br>\n",
    "\n",
    "Normalmente, você resolveria esses valores de peso e viés por meio de um procedimento complicado chamado retropropagação com gradiente descendente estocástico. Para este exemplo, no entanto, já resolvi esses valores de peso e viés, conforme mostrado abaixo.\n",
    "\n",
    "<br><br>\n",
    "\n",
    "$\n",
    "W_{hidden} = \\begin{bmatrix}3.5574801792467 & 8.48639024065542 & 1.59453643090894\\\\4.28982009818168 & 8.35518250953765 & 1.36713925567114\\\\3.7207429234428 & 8.13223257221876 & 1.48165938844881\\end{bmatrix}\n",
    "$\n",
    "\n",
    "$\n",
    "W_{output} = \\begin{bmatrix}4.27394193741564 & 3.656340721696 & 2.63047525734278\\end{bmatrix}\n",
    "$\n",
    "\n",
    "$\n",
    "B_{hidden} = \\begin{bmatrix}-6.67311750917892\\\\-6.34084123159501\\\\-6.10933576744567\\end{bmatrix}\n",
    "$\n",
    "\n",
    "$\n",
    "B_{output} = \\begin{bmatrix}-5.46880991264584\\end{bmatrix}\n",
    "$ \n",
    "<br><br>\n",
    "\n",
    "Eu os declarei em NumPy abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2c5a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "w_hidden = np.array([\n",
    "    [3.55748018, 8.48639024, 1.59453643],\n",
    "    [4.2898201,  8.35518251, 1.36713926],\n",
    "    [3.72074292, 8.13223257, 1.48165939]\n",
    "])\n",
    "\n",
    "w_output = np.array([\n",
    "    [4.27394194, 3.65634072, 2.63047526]\n",
    "])\n",
    "\n",
    "b_hidden = np.array([\n",
    "    [-6.67311751],\n",
    "    [-6.34084123],\n",
    "    [-6.10933577]\n",
    "])\n",
    "\n",
    "b_output = np.array([\n",
    "    [-5.46880991]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723c8c59",
   "metadata": {},
   "source": [
    "Agora aqui está uma operação de multiplicação e adição de matrizes, com as funções não lineares `sigmoid` e `relu`, que receberão uma determinada entrada de uma ou mais cores de fundo $ X $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c24431",
   "metadata": {},
   "source": [
    "$ \n",
    "Y_{pred} = \\text{Sigmoid}(W_{output} \\cdot \\text{ReLU}(W_{hidden} \\cdot X + B_{hidden}) + B_{output})\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a47373d",
   "metadata": {},
   "source": [
    "Vamos implementar toda essa linha no NumPy usando a função `forward_prop()`. Ela gerará as probabilidades sugeridas de ser uma fonte `DARK`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160805da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funções de ativação\n",
    "relu = lambda x: np.maximum(x, 0)\n",
    "sigmoid = lambda x: 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Executa entradas através da rede neural para obter saídas previstas\n",
    "def forward_prop(X):\n",
    "    hidden = relu(w_hidden @ X + b_hidden)\n",
    "    output = sigmoid(w_output @ hidden + b_output)\n",
    "    return output\n",
    "\n",
    "# Calcular previsões para todas as cores de fundo \n",
    "previsoes = forward_prop(X.transpose())\n",
    "previsoes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbcd143",
   "metadata": {},
   "source": [
    "Para resumir melhor esse desempenho (não usaremos práticas recomendadas como divisões de treinamento/teste ou matrizes de confusão aqui), podemos definir todos os valores que sejam pelo menos $ 0,5 $ como $ 1 $ e qualquer valor menor como $ 0 $. Em seguida, podemos comparar os valores reais de $ Y $ com esses novos valores $ Y{pred} $ previstos. Isso nos dá os meios para calcular a porcentagem total de previsões precisas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b0b7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparacao = np.equal((previsoes >= .5).flatten().astype(int), Y)\n",
    "precisao = sum(comparacao.astype(int) / Y.shape[0])\n",
    "print(\"Precisão: \", precisao)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d89feb",
   "metadata": {},
   "source": [
    "## Exercício"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea347de9",
   "metadata": {},
   "source": [
    "Resolva o sistema de equações abaixo usando o NumPy.\n",
    "\n",
    "$\n",
    "4x + 1y - 1z = 1 \\\\\n",
    "1x + 0.5y + 2z = 3 \\\\\n",
    "2x + 1y + 2z = -2\n",
    "$\n",
    "\n",
    "### RESPOSTA A BAIXO\n",
    "\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "v \n",
    "\n",
    "Os valores de $ x $, $y$ e $z$ podem ser calculados encontrando a inversa da matriz de coeficientes e multiplicando-a pelo vetor da direita, como mostrado abaixo.\n",
    "\n",
    "O vetor $\\begin{bmatrix}7.5 & -25.0 & 4.0\\end{bmatrix} $ contém os três valores, respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c50b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from numpy.linalg import inv\n",
    "\n",
    "import sympy as sp \n",
    "\n",
    "# 4x + 1y - z = 1\n",
    "# 1x + 0.5y + 2z = 3\n",
    "# 2x + 1y + 2z = -2\n",
    "\n",
    "A = array([\n",
    "    [4, 1, -1],\n",
    "    [1, 0.5, 2],\n",
    "    [2, 1, 2]\n",
    "])\n",
    "\n",
    "B = array([\n",
    "    1,\n",
    "    3,\n",
    "    -2\n",
    "])\n",
    "\n",
    "X = inv(A) @ B \n",
    "\n",
    "X"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-2024.02-py310",
   "language": "python",
   "name": "conda-env-anaconda-2024.02-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
