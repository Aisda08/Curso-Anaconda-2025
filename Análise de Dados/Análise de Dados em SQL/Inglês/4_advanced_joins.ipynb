{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6db605a3d403873a",
   "metadata": {},
   "source": [
    "# Advanced Join Patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499cad7ece3fe5fc",
   "metadata": {},
   "source": [
    "In this section, we will cover more advanced join patterns that are helpful in data analysis. We will start with a very brief review of the `INNER JOIN`, `LEFT JOIN`, `RIGHT JOIN`, and `FULL OUTER JOIN`. \n",
    "\n",
    "Let's connect to the `company_operations.db` database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0249b5050d8d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd \n",
    "\n",
    "conn = sqlite3.connect('company_operations.db')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3fa075b82c14fe",
   "metadata": {},
   "source": [
    "Let's also tweak pandas to display more rows and not truncate them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4bec6af1f3b85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 999"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ebda94d2e4fc56",
   "metadata": {},
   "source": [
    "## INNER, LEFT, RIGHT, and FULL OUTER JOIN "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d4b944637e4f82",
   "metadata": {},
   "source": [
    "We have used `INNER JOIN` and `LEFT JOIN` a few times in this course. But let's review the fundamental difference between them, and then how they extend to  `RIGHT JOIN` and `FULL OUTER JOIN`. \n",
    "\n",
    "Below we join the `CUSTOMER` and `CUSTOMER_ORDER` table together using an `INNER JOIN`. This allows us to bring in `CUSTOMER` information to show alongside each `CUSTOMER_ORDER`, such as the `CUSTOMER_NAME` and the `SHIP_ADDRESS` (which is concatenated off of four fields).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780c1d0b8d020598",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT CUSTOMER_ORDER_ID,\n",
    "CUSTOMER_NAME,\n",
    "ADDRESS || ' ' || CITY || ', ' || STATE || ' ' || ZIP AS SHIP_ADDRESS,\n",
    "ORDER_DATE,\n",
    "PRODUCT_ID,\n",
    "QUANTITY\n",
    "\n",
    "FROM CUSTOMER INNER JOIN CUSTOMER_ORDER\n",
    "ON CUSTOMER.CUSTOMER_ID = CUSTOMER_ORDER.CUSTOMER_ID\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(sql, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265c99904d47eca4",
   "metadata": {},
   "source": [
    "> Note that `INNER JOIN` can also be aliased as `JOIN`. I personally do not like using this alias. I prefer to be explicit about my intention to use an `INNER JOIN`. There are many types of joins, and when I see a SQL query using `JOIN` rather than an `INNER JOIN`, I assume the composer is not aware there are multiple types of joins. \n",
    "\n",
    "However, recall that there is one `CUSTOMER` without any `CUSTOMER_ORDER` records. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575f464fcaabbed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT * FROM CUSTOMER \n",
    "WHERE CUSTOMER_ID NOT IN (SELECT DISTINCT CUSTOMER_ID FROM CUSTOMER_ORDER)\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(sql, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f402a13c93d42",
   "metadata": {},
   "source": [
    "If we wanted a placeholder record for this `CUSTOMER` record, even if there is no `CUSTOMER_ORDER` record to join to, we can achieve that using a `LEFT JOIN`. This will include all records in the \"left\" table (to the left of `LEFT JOIN` keywords), even if there is no records to join to in the \"right\" table (to the right of `LEFT JOIN` keywords). When there are no records to join to in the \"right\" table, those fields from the \"right\" table will be null. \n",
    "\n",
    "Let's sort on one of those `CUSTOMER_ORDER` fields so the `NULL` records will be at the top that resulted from the `LEFT JOIN`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54395afa349bcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT CUSTOMER_ORDER_ID,\n",
    "CUSTOMER_NAME,\n",
    "ADDRESS || ' ' || CITY || ', ' || STATE || ' ' || ZIP AS SHIP_ADDRESS,\n",
    "ORDER_DATE,\n",
    "PRODUCT_ID,\n",
    "QUANTITY\n",
    "\n",
    "FROM CUSTOMER LEFT JOIN CUSTOMER_ORDER\n",
    "ON CUSTOMER.CUSTOMER_ID = CUSTOMER_ORDER.CUSTOMER_ID\n",
    "\n",
    "ORDER BY ORDER_DATE\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(sql, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947cc15f6360098b",
   "metadata": {},
   "source": [
    "`LEFT JOIN` is a shorthand alias for `LEFT OUTER JOIN`, so you can use those keywords as well. Note they are the same. \n",
    "\n",
    "The `RIGHT JOIN` (or `RIGHT OUTER JOIN`) is exactly the same as `LEFT JOIN`, except it flips the direction. This will include all records in the \"right\" table (to the right of `RIGHT JOIN` keywords), even if there is no records to join to in the \"left\" table (to the right of `RIGHT JOIN` keywords). When there are no records to join to in the \"left\" table, those fields from the \"left\" table will be null. \n",
    "\n",
    "We can achieve the exact same result of our previous `LEFT JOIN` query by specifying `CUSTOMER_ORDER RIGHT JOIN CUSTOMER`instead of `CUSTOMER LEFT JOIN CUSTOMER_ORDER`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dabdf5adcf656e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT CUSTOMER_ORDER_ID,\n",
    "CUSTOMER_NAME,\n",
    "ADDRESS || ' ' || CITY || ', ' || STATE || ' ' || ZIP AS SHIP_ADDRESS,\n",
    "ORDER_DATE,\n",
    "PRODUCT_ID,\n",
    "QUANTITY\n",
    "\n",
    "FROM CUSTOMER_ORDER RIGHT JOIN CUSTOMER\n",
    "ON CUSTOMER.CUSTOMER_ID = CUSTOMER_ORDER.CUSTOMER_ID\n",
    "\n",
    "ORDER BY ORDER_DATE\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(sql, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf1beb67ed770f6",
   "metadata": {},
   "source": [
    "Because any `RIGHT JOIN` query can be composed as a `LEFT JOIN`, it is rarely used. It is best practice to use a `LEFT JOIN`. The `FULL OUTER JOIN` does a `LEFT JOIN` and `RIGHT JOIN` simultaneously, including all records from both the \"left\" and \"right\" tables. Because orphaned records are often illegal in relational databases (e.g. a child without a parent, a `CUSTOMER_ORDER` without an existing `CUSTOMER`), it is rarely used. It is perfectly fine to have a parent without a child though, as seen with a `CUSTOMER` record without `CUSTOMER_ORDER` records.\n",
    "\n",
    "We can also join more than two tables. Below I joing to a third table called `PRODUCT` to bring in product information, like the `PRODUCT_NAME` and `PRICE`. I have to use another `LEFT JOIN` here rather than an `INNER JOIN` because the `PRODUCT_ID` will be null for \"Alpha Medical\" since it has no orders. `LEFT JOIN` will tolerate null values in its join condition, but `RIGHT JOIN` will omit them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccba4b9a5d3213c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT CUSTOMER_ORDER_ID,\n",
    "CUSTOMER_NAME,\n",
    "ADDRESS || ' ' || CITY || ', ' || STATE || ' ' || ZIP AS SHIP_ADDRESS,\n",
    "ORDER_DATE,\n",
    "PRODUCT.PRODUCT_ID,\n",
    "PRODUCT_NAME,\n",
    "PRICE,\n",
    "QUANTITY\n",
    "\n",
    "FROM CUSTOMER LEFT JOIN CUSTOMER_ORDER\n",
    "ON CUSTOMER.CUSTOMER_ID = CUSTOMER_ORDER.CUSTOMER_ID\n",
    "\n",
    "LEFT JOIN PRODUCT\n",
    "ON PRODUCT.PRODUCT_ID = CUSTOMER_ORDER.PRODUCT_ID\n",
    "\n",
    "ORDER BY ORDER_DATE\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(sql, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f33767784997ce",
   "metadata": {},
   "source": [
    "With all three tables joined, we can introduce a `GROUP BY` and some expressions to find the total revenue by `CUSTOMER`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcdb06e23ff3e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT \n",
    "CUSTOMER.CUSTOMER_ID,\n",
    "CUSTOMER_NAME,\n",
    "COALESCE(SUM(PRICE * QUANTITY), 0) AS TOTAL_REVENUE\n",
    "\n",
    "FROM CUSTOMER LEFT JOIN CUSTOMER_ORDER\n",
    "ON CUSTOMER.CUSTOMER_ID = CUSTOMER_ORDER.CUSTOMER_ID\n",
    "\n",
    "LEFT JOIN PRODUCT\n",
    "ON PRODUCT.PRODUCT_ID = CUSTOMER_ORDER.PRODUCT_ID\n",
    "\n",
    "GROUP BY 1, 2\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(sql, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6761fdb648ea711",
   "metadata": {},
   "source": [
    "## Volatile/Temporary Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ed5f580116c0df",
   "metadata": {},
   "source": [
    "Especially when you are doing data analysis, there may be times you need to injection a temporary table into the database with some data, often to join to. Let's say you have a spreadsheet of discounts you want to give to certain customers discounts for certain products. Rather than create a monstrous amount of `CASE` expressions to handle this, you can instead create a **temporary table** that will put data into the database until you disconnect. \n",
    "\n",
    "It follows the exact same `CREATE TABLE` convention, but instead you specify it as `CREATE TEMP TABLE`. Other platforms, like Teradata, may call it a `VOLATILE TABLE`.\n",
    "\n",
    "Let's first create a pandas `DataFrame` of our discounts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa34be8e15662c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "discounts = pd.DataFrame({\n",
    "    'customer_id' : [2,2,2,4,4,4,7,7,7,7,7],\n",
    "    'product_id' : [4,5,9,3,8,6,5,11,12,13,15],\n",
    "    'discounts' : [.1, .12, .2, .1, .3, .15, .05, .12, .15, .35, .05]\n",
    "})\n",
    "\n",
    "discounts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554032d6db66e1ff",
   "metadata": {},
   "source": [
    "Let's then create our temporary table `DISCOUNT` and upload the pandas `DataFrame` to it using `executemany()` and an `INSERT` template. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b3850732698932",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_sql = \"\"\"\n",
    "CREATE TEMP TABLE DISCOUNT ( \n",
    "    CUSTOMER_ID INTEGER NOT NULL, \n",
    "    PRODUCT_ID INTEGER NOT NULL, \n",
    "    DISCOUNT_RATE DOUBLE NOT NULL\n",
    ");\n",
    "\"\"\"\n",
    "conn.execute(create_sql)\n",
    "\n",
    "insert_sql = 'INSERT INTO DISCOUNT (CUSTOMER_ID, PRODUCT_ID, DISCOUNT_RATE) VALUES (?, ?, ?)'\n",
    "conn.executemany(insert_sql, discounts.values)\n",
    "\n",
    "pd.read_sql(\"SELECT * FROM DISCOUNT\", conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2736aa-10e4-4dad-b863-58109118158f",
   "metadata": {},
   "source": [
    "We can now join to the `DISCOUNT` table and apply the discounts!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77705e0357595ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT CUSTOMER_ORDER_ID, \n",
    "CUSTOMER_ORDER.CUSTOMER_ID,\n",
    "CUSTOMER_ORDER.PRODUCT_ID, \n",
    "PRICE,\n",
    "DISCOUNT_RATE, \n",
    "PRICE * (1.0 - DISCOUNT_RATE) AS DISCOUNT_PRICE\n",
    "\n",
    "FROM CUSTOMER_ORDER INNER JOIN PRODUCT\n",
    "ON CUSTOMER_ORDER.PRODUCT_ID = PRODUCT.PRODUCT_ID\n",
    "\n",
    "LEFT JOIN DISCOUNT\n",
    "ON CUSTOMER_ORDER.CUSTOMER_ID = DISCOUNT.CUSTOMER_ID\n",
    "AND CUSTOMER_ORDER.PRODUCT_ID = DISCOUNT.PRODUCT_ID\n",
    "\n",
    "WHERE DISCOUNT_RATE IS NOT NULL\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(sql, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2541bd429a69763",
   "metadata": {},
   "source": [
    "## Self Joins and Non-Equal Joins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683deaa6313acfb9",
   "metadata": {},
   "source": [
    "After all the crazy things we did with subqueries and derived tables, it's probably no surprise we can join a table to itself. This can be helpful to, for example, get the previous day's order `QUANITTY` relative to each record. We alias `CUSTOMER_ORDER` twice as `o1` and `o2`. Think of this as creating two separate copies of that table and joining them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30eef5dc35bc1fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT o1.CUSTOMER_ORDER_ID,\n",
    "o1.CUSTOMER_ID,\n",
    "o1.PRODUCT_ID,\n",
    "o1.ORDER_DATE,\n",
    "o1.QUANTITY,\n",
    "o2.QUANTITY AS PREV_DAY_QUANTITY\n",
    "\n",
    "FROM CUSTOMER_ORDER o1 LEFT JOIN CUSTOMER_ORDER o2\n",
    "\n",
    "ON o1.CUSTOMER_ID = o2.CUSTOMER_ID\n",
    "AND o1.PRODUCT_ID = o2.PRODUCT_ID\n",
    "AND o2.ORDER_DATE = date(o1.ORDER_DATE, '-1 day')\n",
    "\n",
    "WHERE o1.ORDER_DATE BETWEEN '2024-03-05' AND '2024-03-11'\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(sql, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a9a8afdcaa3d1d",
   "metadata": {},
   "source": [
    "If you want to get previous quantity for each record, even if it is earlier than the previous day, we can achieve this using a correlated subquery. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e350c09c07f6c46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT ORDER_DATE,\n",
    "PRODUCT_ID,\n",
    "CUSTOMER_ID,\n",
    "QUANTITY,\n",
    "(\n",
    "    SELECT QUANTITY\n",
    "    FROM CUSTOMER_ORDER c2\n",
    "    WHERE c1.ORDER_DATE > c2.ORDER_DATE\n",
    "    AND c1.PRODUCT_ID = c2.PRODUCT_ID\n",
    "    AND c1.CUSTOMER_ID = c2.CUSTOMER_ID\n",
    "    ORDER BY ORDER_DATE DESC\n",
    "    LIMIT 1\n",
    ") as PREV_QTY\n",
    "FROM CUSTOMER_ORDER c1\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(sql, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b168ef1df6ea74",
   "metadata": {},
   "source": [
    "You also do not have to join strictly on equality. We can join a table to itself, but use this to sum records from previous dates sharing the same `PRODUCT_ID` and `CUSTOMER_ID`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9013ec1dec5faa45",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT c1.ORDER_DATE,\n",
    "c1.PRODUCT_ID,\n",
    "c1.CUSTOMER_ID,\n",
    "c1.QUANTITY,\n",
    "SUM(c2.QUANTITY) as ROLLING_QTY\n",
    "\n",
    "FROM CUSTOMER_ORDER c1 INNER JOIN CUSTOMER_ORDER c2\n",
    "ON c1.PRODUCT_ID = c2.PRODUCT_ID\n",
    "AND c1.CUSTOMER_ID = c2.CUSTOMER_ID\n",
    "AND c1.ORDER_DATE >= c2.ORDER_DATE\n",
    "\n",
    "GROUP BY 1, 2, 3, 4\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(sql, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4bf55e8fff901b",
   "metadata": {},
   "source": [
    "We will learn how to leverage windowing functions later that will make these tasks easier, but we can still leverage these tools when we need to flexibly create more complex logic. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af205680db553100",
   "metadata": {},
   "source": [
    "# Cross Joins "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6fee249301b687",
   "metadata": {},
   "source": [
    "A **cross join** is a special type of join that creates all possible combinations between two or more tables. This is also known as a **cartesian join**. For example, we can pair every possible `PRODUCT_ID` with every possible `CUSTOMER_ID`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad6fe7af7dcaa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT PRODUCT_ID, CUSTOMER_ID \n",
    "FROM PRODUCT CROSS JOIN CUSTOMER\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(sql, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d883c4674ae731",
   "metadata": {},
   "source": [
    "Why could this be useful? Let's say we have this query below that finds the total revenue by `CUSTOMER_ID` and `PRODUCT_ID` for a specific date. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d037280b9d93025",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT CUSTOMER.CUSTOMER_ID, \n",
    "PRODUCT.PRODUCT_ID, \n",
    "SUM(PRICE * QUANTITY) AS TOTAL_REVENUE\n",
    "\n",
    "FROM CUSTOMER LEFT JOIN CUSTOMER_ORDER\n",
    "ON CUSTOMER.CUSTOMER_ID = CUSTOMER_ORDER.CUSTOMER_ID\n",
    "\n",
    "LEFT JOIN PRODUCT \n",
    "ON PRODUCT.PRODUCT_ID = CUSTOMER_ORDER.PRODUCT_ID\n",
    "\n",
    "WHERE ORDER_DATE = '2024-03-01'\n",
    "GROUP BY 1, 2 \n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(sql, conn)\n",
    "## Recursive Self Joins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa5b8cfff62be3c",
   "metadata": {},
   "source": [
    "However, we want to see all customers and products even if there were no orders on that given day for that `PRODUCT_ID` and `CUSTOMER_ID`. We can package that query into a common table expression, and `LEFT JOIN` it to that `CROSS JOIN` query combining every `PRODUCT_ID` and `CUSTOMER_ID`. We will also `COALESCE()` null values to 0 when there were no sales. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35914672690a40d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "WITH totals AS ( \n",
    "    SELECT CUSTOMER.CUSTOMER_ID, \n",
    "    PRODUCT.PRODUCT_ID, \n",
    "    SUM(PRICE * QUANTITY) AS TOTAL_REVENUE\n",
    "    \n",
    "    FROM CUSTOMER LEFT JOIN CUSTOMER_ORDER\n",
    "    ON CUSTOMER.CUSTOMER_ID = CUSTOMER_ORDER.CUSTOMER_ID\n",
    "    \n",
    "    LEFT JOIN PRODUCT \n",
    "    ON PRODUCT.PRODUCT_ID = CUSTOMER_ORDER.PRODUCT_ID\n",
    "    \n",
    "    WHERE ORDER_DATE = '2024-03-01'\n",
    "    GROUP BY 1, 2 \n",
    "), \n",
    "\n",
    "all_combos AS ( \n",
    "    SELECT PRODUCT_ID, CUSTOMER_ID \n",
    "    FROM PRODUCT CROSS JOIN CUSTOMER\n",
    ")\n",
    "\n",
    "SELECT all_combos.PRODUCT_ID, \n",
    "all_combos.CUSTOMER_ID,\n",
    "COALESCE(totals.TOTAL_REVENUE, 0) AS TOTAL_REVENUE\n",
    "\n",
    "FROM all_combos LEFT JOIN totals\n",
    "ON all_combos.CUSTOMER_ID = totals.CUSTOMER_ID\n",
    "AND all_combos.PRODUCT_ID = totals.PRODUCT_ID\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(sql, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a1e047e65364d4",
   "metadata": {},
   "source": [
    "Be mindful to not create combinatorial explosions with cross joins, as creating too many combinations can slow down your queries greatly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b640b00c2543b3",
   "metadata": {},
   "source": [
    "## Recursive Self Joins "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f98c15efe48241",
   "metadata": {},
   "source": [
    "Let's take a look at a different table: the `EMPLOYEE` table. Notice the `MANAGER_ID` column has values that point to other `EMPLOYEE` records. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511d1be7627d9027",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql(\"SELECT * FROM EMPLOYEE\", conn, index_col='ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3e3d4595293134",
   "metadata": {},
   "source": [
    "You can self join this table and go one level up, but how do we go up the whole hierarchy? Let's focus on one employee with `FIRST_NAME` \"Mag\" and an `ID` of \"29\". We can use a special type of common table expression that is `RECURSIVE`.  We seed with a starting value of `29` and recursively append the ID's up the whole hierarchy until there are no more (when it hits the CEO). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795cb71c9f22feaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "-- generates a list of employee ID's hierarchical to Mag\n",
    "WITH RECURSIVE hierarchy_of_mag(x) AS (\n",
    " SELECT 29 -- start with Mag's ID\n",
    " UNION ALL -- append each manager ID recursively\n",
    " SELECT MANAGER_ID\n",
    " FROM hierarchy_of_mag INNER JOIN EMPLOYEE\n",
    " ON EMPLOYEE.ID = hierarchy_of_mag.x -- employee ID must equal previous recursion\n",
    ")\n",
    "\n",
    "SELECT * FROM hierarchy_of_mag;\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(sql, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e23c3ff9f019aa6",
   "metadata": {},
   "source": [
    "We can use this set of ID's to qualify those employees in that hierarchy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c2eb1d793a68f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "-- generates a list of employee ID's hierarchical to Mag\n",
    "WITH RECURSIVE hierarchy_of_mag(x) AS (\n",
    " SELECT 29 -- start with Mag's ID\n",
    " UNION ALL -- append each manager ID recursively\n",
    " SELECT MANAGER_ID \n",
    " FROM hierarchy_of_mag INNER JOIN EMPLOYEE\n",
    " ON EMPLOYEE.ID = hierarchy_of_mag.x -- employee ID must equal previous recursion\n",
    ")\n",
    "\n",
    "SELECT * FROM EMPLOYEE WHERE ID IN hierarchy_of_mag;\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(sql, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44fa9a62089244d",
   "metadata": {},
   "source": [
    "Recursive queries are also helpful for generating a range of consecutive values, like a range of integers or dates/times. Here is a range of integers from 1 to 1000.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4455ec09ac0d15a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\" \n",
    "WITH RECURSIVE integers(i) AS (\n",
    "    SELECT 1\n",
    "        UNION ALL\n",
    "    SELECT i + 1 \n",
    "    FROM integers\n",
    "    WHERE i < 1000\n",
    ")\n",
    "\n",
    "SELECT * FROM integers\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(sql, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b290ad9159815b29",
   "metadata": {},
   "source": [
    "And here is an enumeration of dates from now until December 31, 2030. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef7097f77429c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\" \n",
    "WITH RECURSIVE calendar_dates(dt) AS (\n",
    "    SELECT date('now')\n",
    "        UNION ALL\n",
    "    SELECT date(dt, '+1 day')\n",
    "    FROM calendar_dates\n",
    "    WHERE dt < '2030-12-31'\n",
    ")\n",
    "SELECT * FROM calendar_dates\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(sql, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55448992768a0f52",
   "metadata": {},
   "source": [
    "Returning to our earlier `CROSS JOIN` example, we can leverage this date enumeration to fill in gaps not only for every `CUSTOMER_ID` and `PRODUCT_ID`, but also the `ORDER_DATE`. In other words, we can see every `CUSTOMER_ID` and `PRODUCT_ID` represented in our query for every `ORDER_DATE`, even if there were not any orders. Just be sure to list the `RECURSIVE` queries first in your common table expressions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cec0bf15633fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "WITH RECURSIVE calendar_dates(dt) AS (\n",
    "    SELECT date('2020-01-01')\n",
    "        UNION ALL\n",
    "    SELECT date(dt, '+1 day')\n",
    "    FROM calendar_dates\n",
    "    WHERE dt <'2099-12-31'\n",
    "), \n",
    "\n",
    "totals AS ( \n",
    "    SELECT CUSTOMER.CUSTOMER_ID, \n",
    "    PRODUCT.PRODUCT_ID, \n",
    "    ORDER_DATE,\n",
    "    SUM(PRICE * QUANTITY) AS TOTAL_REVENUE\n",
    "    \n",
    "    FROM CUSTOMER INNER JOIN CUSTOMER_ORDER\n",
    "    ON CUSTOMER.CUSTOMER_ID = CUSTOMER_ORDER.CUSTOMER_ID\n",
    "    \n",
    "    INNER JOIN PRODUCT \n",
    "    ON PRODUCT.PRODUCT_ID = CUSTOMER_ORDER.PRODUCT_ID\n",
    "    \n",
    "    GROUP BY 1, 2, 3\n",
    "), \n",
    "\n",
    "all_combos AS ( \n",
    "    SELECT PRODUCT_ID, CUSTOMER_ID, dt\n",
    "    FROM PRODUCT CROSS JOIN CUSTOMER \n",
    "    CROSS JOIN calendar_dates\n",
    "    WHERE dt BETWEEN '2024-03-01' AND '2024-03-31'\n",
    ")\n",
    "SELECT all_combos.dt as ORDER_DATE, \n",
    "all_combos.PRODUCT_ID, \n",
    "all_combos.CUSTOMER_ID,\n",
    "COALESCE(totals.TOTAL_REVENUE, 0) AS TOTAL_REVENUE\n",
    "\n",
    "FROM all_combos LEFT JOIN totals\n",
    "ON all_combos.CUSTOMER_ID = totals.CUSTOMER_ID\n",
    "AND all_combos.PRODUCT_ID = totals.PRODUCT_ID\n",
    "AND all_combos.dt = totals.ORDER_DATE\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(sql, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58343cc313d4e566",
   "metadata": {},
   "source": [
    "Let's look at one last example. Take a look at the `EMPLOYEE_AIR_TRAVEL` table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5c805164fa2ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql(\"SELECT * FROM EMPLOYEE_AIR_TRAVEL\", conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5d0652023cd35b",
   "metadata": {},
   "source": [
    "Note the `NUM_OF_PASSENGERS` column indicates the number of passengers on that ticket. Let's say we wanted to break these up into multiple records, so a `NUM_OF_PASSENGERS` of \"3\" would turn that one record into three copies of the record. We can use a `RECURSIVE` enumeration of integers to achieve this, copying the record as many times as we need. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b1858f89e42b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "WITH RECURSIVE integers(i) AS (\n",
    "    SELECT 1\n",
    "        UNION ALL\n",
    "    SELECT i + 1 \n",
    "    FROM integers\n",
    "    WHERE i < 100\n",
    ")\n",
    "\n",
    "SELECT BOOKING_ID, \n",
    "BOOKED_EMPLOYEE_ID,\n",
    "DEPARTURE_DATE,\n",
    "ORIGIN,\n",
    "DESTINATION,\n",
    "FARE_PRICE,\n",
    "integers.i AS PASSENGER_NUMBER\n",
    "FROM EMPLOYEE_AIR_TRAVEL CROSS JOIN integers\n",
    "ON integers.i <= NUM_OF_PASSENGERS\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(sql, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2ac1dfab1549d0",
   "metadata": {},
   "source": [
    "We can also use thes integers to enumerate copies of records for another purpose: break up the `ORIGIN` and `DESTINATION` into two separate records. This can help us find how much we are spending for employees to fly through each `AIRPORT` regardless if that `AIRPORT` is the `ORIGIN` or the `DESTINATION`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6281e88c7bdcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "WITH RECURSIVE integers(i) AS (\n",
    "    SELECT 1\n",
    "        UNION ALL\n",
    "    SELECT i + 1 \n",
    "    FROM integers\n",
    "    WHERE i < 100\n",
    ")\n",
    "\n",
    "SELECT\n",
    "CASE WHEN integers.i == 1 THEN ORIGIN ELSE DESTINATION END AS AIRPORT,\n",
    "SUM(FARE_PRICE * NUM_OF_PASSENGERS) AS AIRPORT_COST\n",
    "FROM EMPLOYEE_AIR_TRAVEL CROSS JOIN integers\n",
    "ON integers.i <= 2\n",
    "GROUP BY AIRPORT\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(sql, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcf8161db25b665",
   "metadata": {},
   "source": [
    "As you can see, recursive queries are very powerful and are highly underutilized and underrated. Use them to fill in gaps in your data, duplicate and modify records, or simply generate a range of values including integers and dates/times."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af51533857dc1d9",
   "metadata": {},
   "source": [
    "## Exercise "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c51c6ff2768d0b9",
   "metadata": {},
   "source": [
    "For every calendar date and `PRODUCT_ID`, show the total quantity ordered for the date range of `2024-01-01` to `2024-02-28`. A lot of boilerplate has been coded already. Just fill in the question marks \"?\". \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c15729f4526274",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "WITH RECURSIVE calendar_dates(dt) AS (\n",
    "    SELECT date('2020-01-01')\n",
    "        UNION ALL\n",
    "    SELECT date(dt, '+1 day')\n",
    "    FROM calendar_dates\n",
    "    WHERE dt <'2099-12-31'\n",
    "), \n",
    "\n",
    "product_totals_by_date AS ( \n",
    "    ?\n",
    "), \n",
    "\n",
    "all_combos AS ( \n",
    "    SELECT ?, ?\n",
    "    FROM PRODUCT ? ? calendar_dates\n",
    "    WHERE dt BETWEEN '2024-01-01' AND '2024-02-28'\n",
    ")\n",
    "SELECT all_combos.dt as ORDER_DATE, \n",
    "all_combos.PRODUCT_ID, \n",
    "COALESCE(?, 0) AS TOTAL_REVENUE\n",
    "\n",
    "FROM all_combos LEFT JOIN product_totals_by_date\n",
    "ON all_combos.PRODUCT_ID = ?\n",
    "AND all_combos.dt = ?\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(sql, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383deda4982fe1f8",
   "metadata": {},
   "source": [
    "\n",
    "### SCROLL DOWN FOR ANSWER\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "v "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a562add359bd03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "WITH RECURSIVE calendar_dates(dt) AS (\n",
    "    SELECT date('2020-01-01')\n",
    "        UNION ALL\n",
    "    SELECT date(dt, '+1 day')\n",
    "    FROM calendar_dates\n",
    "    WHERE dt <'2099-12-31'\n",
    "), \n",
    "\n",
    "product_totals_by_date AS ( \n",
    "    SELECT PRODUCT.PRODUCT_ID, \n",
    "    ORDER_DATE,\n",
    "    SUM(PRICE * QUANTITY) AS TOTAL_REVENUE\n",
    "    \n",
    "    FROM PRODUCT INNER JOIN CUSTOMER_ORDER \n",
    "    ON PRODUCT.PRODUCT_ID = CUSTOMER_ORDER.PRODUCT_ID\n",
    "    \n",
    "    GROUP BY 1,2\n",
    "), \n",
    "\n",
    "all_combos AS ( \n",
    "    SELECT PRODUCT_ID, dt\n",
    "    FROM PRODUCT CROSS JOIN calendar_dates\n",
    "    WHERE dt BETWEEN '2024-01-01' AND '2024-02-28'\n",
    ")\n",
    "SELECT all_combos.dt as ORDER_DATE, \n",
    "all_combos.PRODUCT_ID, \n",
    "COALESCE(product_totals_by_date.TOTAL_REVENUE, 0) AS TOTAL_REVENUE\n",
    "\n",
    "FROM all_combos LEFT JOIN product_totals_by_date\n",
    "ON all_combos.PRODUCT_ID = product_totals_by_date.PRODUCT_ID\n",
    "AND all_combos.dt = product_totals_by_date.ORDER_DATE\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(sql, conn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-2024.02-py310",
   "language": "python",
   "name": "conda-env-anaconda-2024.02-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
