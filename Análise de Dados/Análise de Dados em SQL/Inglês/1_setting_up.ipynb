{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f2089ac36a20de5",
   "metadata": {},
   "source": [
    "# Setting Up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942663dd9e2f3294",
   "metadata": {},
   "source": [
    "In this section, we are going to discuss what is SQL and how to set up SQLite in a Python environment. If you are completely unfamiliar with SQL (structured query language), it might be a good idea to take the other Anaconda course *[Introduction to SQL](https://learning.anaconda.cloud/introduction-to-sql)*. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ac659eb551c1f8",
   "metadata": {},
   "source": [
    "## What is SQL (Structured Query Language?) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0704691831c15c",
   "metadata": {},
   "source": [
    "**SQL** stands for structured query language and is used to retrieve, manipulate, and write data. In this course we will put emphasis on retrieving and manipulating data for the purpose of analytics. While SQL is traditionally associated with relational databases, SQL has continued to be popular enough to be implemented in NoSQL databases (\"Not only SQL\") as well as \"big data\" platforms like Apache Spark and Trino. Even though it is 50 years old, SQL continues to be a necessary skill for any data professional and a go-to language for working with data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76676957f68e321",
   "metadata": {},
   "source": [
    "## What Are Relational Databases? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10d3f73c24390c9",
   "metadata": {},
   "source": [
    "**Relational database management systems (RDBMS)** are repositories containing tables that may have relationships to each other. if you have a table called `EMPLOYEE` and another called `EMPLOYEE_AIR_TRAVEL` that tracks their flights for business travel, we can reasonably expect the latter table to have a field (perhaps called `BOOKED_EMPLOYEE_ID` tying it to the `EMPLOYEE_ID` of the first table.  \n",
    "\n",
    "![](./resource/uXeyKTO9.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880068e404219543",
   "metadata": {},
   "source": [
    "Storing data in this manner where we separate different types of data is called **normalization**, and it efficiently reduces storage space and minimizes duplicative data. After all, why would we store the `FIRST_NAME` and `LAST_NAME` of each employee for every single `EMPLOYEE_AIR_TRAVEL` booking? Instead, we just use an integer key to refer the employee information.\n",
    "\n",
    "It is important to note that in an analytics context, a **data warehouse** is an entity you will frequently interact with. Relational databases can be used for live operations. Examples would be a database managing the baggage and customers flowing through an airport in real time, or capturing and fulfilling orders on a shopping website. We do not hit analytical queries against these databases because it could slow them down. Instead, we have data that is regularly extracted, transformed, and loaded (ETL) into a data warehouse that serves analytical users trying to get insights from the business without disrupting the operational databases. \n",
    "\n",
    "There are other types of repositories that store and provide interfaces with data such data lakes, data lakehouses, and data fabrics. But generally, you will find SQL can be used to interface with many of these data platforms. For our purposes, we will use a relational datababase platform (SQLite) which is built right into Python. But you can extend this knowledge to other data platforms. \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb29b52ca568f09",
   "metadata": {},
   "source": [
    "## Why SQLite? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57233a7833faad",
   "metadata": {},
   "source": [
    "**SQLite** is a relational database platform just like [PostgreSQL](https://www.postgresql.org), [Oracle](https://www.oracle.com/database/technologies/appdev/sql.html), or [Microsoft SQL Server](https://www.microsoft.com/en-us/sql-server). However what is unique about it is it does not require a server. Instead the database is simply stored as a file on your local machine and you use a library or user interface to open it. Python already contains SQLite support by default so you do not have to install it. It also complies to [DBI API 2.0 specified by PEP 249](https://docs.python.org/3/library/sqlite3.html). This means that other database platform packages that comply to this standard (including [Microsoft SQL Server](https://pypi.org/project/pymssql/) and [Oracle](https://pypi.org/project/cx-Oracle/)) can be worked with in the same way we will use SQLite. Therefore, everything you learn in this training can apply to most major database platforms!  \n",
    "\n",
    "> If you want to write SQL against a SQLite database with a graphical user interface, there are many tools that provide this. My personal favorites are [SQLiteOnline](https://docs.python.org/3/library/sqlite3.html) and [SQLiteStudio](https://sqlitestudio.pl/). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1435ea7a2794e81f",
   "metadata": {},
   "source": [
    "## Setting Up "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb51d7c1ba1b157",
   "metadata": {},
   "source": [
    "As stated earlier, SQLite is already built-in with Python 3. If you use other platforms like [Microsoft SQL Server](https://pypi.org/project/pymssql/) or [Oracle](https://pypi.org/project/cx-Oracle/) you will need to `pip install` those respective packages that comply to the DBI-API 2.0 standard. \n",
    "\n",
    "We do however need to get the SQLite file containing a sample database we will work examples with. For convenience, we can use download the file straight [off the Github repository](https://github.com/thomasnield/anaconda_intro_to_sql/) and put it in our working Python directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a31f28dcbb2ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "#urllib.request.urlretrieve(\"https://github.com/thomasnield/anaconda_intro_to_sql/blob/main/company_operations.db?raw=true\", \"company_operations.db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39464ccb55cdcfe0",
   "metadata": {},
   "source": [
    "We are now ready to connect to the database. We will create a connection using the `sqlite3` package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4093c0fe52a402d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect('company_operations.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee1bcba5c2fbacc",
   "metadata": {},
   "source": [
    "We will also bring in `pandas` which has a very convenient function `read_sql` to execute a SQL query against a connection and package the results in a `DataFrame`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38c9abb3b657211",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sql = \"SELECT * FROM EMPLOYEE_AIR_TRAVEL\"\n",
    "pd.read_sql(sql, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b123f514dad3a6ba",
   "metadata": {},
   "source": [
    "Notice above that we display the query results in a `DataFrame`. Let's talk about running queries next. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631eae91f933e69e",
   "metadata": {},
   "source": [
    "## Why SQL Instead of Pandas? \n",
    "\n",
    "As we will be learning how to do analytics with SQL, you might be wondering why not just use pandas since it can do so many of these tasks too. SQL and Pandas are not competitors, but rather two different tools for two different environments. When you have many terabytes of data stored on a relational database, you will likely be unable to process that data locally on your machine using pandas. It makes sense to let SQL do the heavy computation on the server side (which is optimized to process the data it is storing) and have pandas simply receive the results. Conversely, SQL may be less equipped for machine learning tasks and merging disparate data sources, or running more elaborate algorithms that Python and pandas are better equipped to do. \n",
    "\n",
    "Generally, it is a good practice when working with a relational database to have the database server do the computation work where possible and have the Python environment consume the results. Keep both tools in your back pocket, and use them situationally where they make sense. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96239d86258f6907",
   "metadata": {},
   "source": [
    "## Running Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5065fa55d2952bf1",
   "metadata": {},
   "source": [
    "Hopefully you have worked with SQL before, and if not check out the other Anaconda course *[Introduction to SQL](https://learning.anaconda.cloud/introduction-to-sql)*. Here we will do a basic review of the `SELECT` operation and common tasks we will do. \n",
    "\n",
    "`SELECT * FROM CUSTOMER` will select all fields from the `CUSTOMER` table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd3623dceac6957",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"SELECT * FROM CUSTOMER\"\n",
    "pd.read_sql(sql, conn)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "832ba15982914298",
   "metadata": {},
   "source": [
    "You can also select specific fields using comma-separated field names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c2940947c655b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"SELECT CUSTOMER_ID, CUSTOMER_NAME FROM CUSTOMER\"\n",
    "pd.read_sql(sql, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1603b722ccd99c0",
   "metadata": {},
   "source": [
    "To filter rows based on one or more conditions, use the `WHERE` clause. Use the `AND` and `OR` keywords to specify multiple conditions, using `AND` to require all conditions to be met or `OR` for at least one condition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988db90b35fc85b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT * FROM CUSTOMER \n",
    "WHERE STATE = 'TX' AND CATEGORY = 'COMMERCIAL'\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(sql, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4b009a602b5f89",
   "metadata": {},
   "source": [
    "Use parantheses to group up multiple conditions, such as whether there was `SNOW` or sleet occurred. For sleet to occur, there has to be rain and the temperature must be less than or equal to 32 degrees Fahrenheit, so we treat this as a single condition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268bdb5ec0533d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT * FROM WEATHER_MONITOR \n",
    "WHERE SNOW > 0 OR (RAIN = 1 AND TEMPERATURE <= 32)\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(sql, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e706ed3c357a5d",
   "metadata": {},
   "source": [
    "Use functions like `SUM`, `MIN`, `MAX`, `COUNT`, and `AVG` to aggregate a column. Below we get the total rain when tornados occurred. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461200ea92dcdfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT SUM(RAIN) FROM WEATHER_MONITOR \n",
    "WHERE TORNADO = 1 \n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(sql, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fa41563e8ccacd",
   "metadata": {},
   "source": [
    "Use `GROUP BY` to slice aggregate functions on one or more fields/expressions. Below, we get the total rain by each report date. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cae8d90ddf768c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT REPORT_DATE, \n",
    "SUM(RAIN) AS TOTAL_RAIN\n",
    "\n",
    "FROM WEATHER_MONITOR \n",
    "WHERE TORNADO = 1 \n",
    "GROUP BY REPORT_DATE \n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(sql, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36febd7acc86f3d",
   "metadata": {},
   "source": [
    "Another nuance to note is that numeric values (including binary 1/0 values) as well as floating point values do not have to quotes when declaring a value. But texts, dates/times, and other data types typically have to wrap values in quotes as shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00c37b01667f8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT * FROM WEATHER_MONITOR\n",
    "WHERE REPORT_CODE = '3J3YUUD'\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(sql, conn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d034931b3ae0e",
   "metadata": {},
   "source": [
    "## EXERCISE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac4b68a875b3355",
   "metadata": {},
   "source": [
    "Complete the SQL query below (by replacing the question marks \"?\") to find the minimum and maximum temperature by year since March 1, 2024. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbefb275856f022",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT strftime('%m', REPORT_DATE) AS YEAR, \n",
    "? AS MIN_TEMP, \n",
    "? AS MAX_TEMP\n",
    "\n",
    "FROM WEATHER_MONITOR\n",
    "WHERE ? >= ?\n",
    "GROUP BY ?\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(sql, conn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea3aebb3cf7d9c4",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### SCROLL DOWN FOR ANSWER\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "v "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2a757935979352",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT strftime('%m', REPORT_DATE) AS YEAR, \n",
    "MIN(TEMPERATURE) AS MIN_TEMP, \n",
    "MAX(TEMPERATURE) AS MAX_TEMP\n",
    "\n",
    "FROM WEATHER_MONITOR\n",
    "WHERE REPORT_DATE >= '2024-03-01'\n",
    "GROUP BY 1 \n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(sql, conn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-2024.02-py310",
   "language": "python",
   "name": "conda-env-anaconda-2024.02-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
