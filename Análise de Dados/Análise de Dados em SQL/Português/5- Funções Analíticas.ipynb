{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1300efd7166c362a",
   "metadata": {},
   "source": [
    "# Funções Analíticas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6912653075291944",
   "metadata": {},
   "source": [
    "**Funções analíticas**, também conhecidas como **funções de janela**, são uma ferramenta poderosa em SQL para um registro anexar contextos de outros registros. Isso fará sentido com os vários exemplos que demonstraremos. Embora mostremos maneiras mais simples de realizar tarefas anteriores que realizamos com subconsultas, tabelas derivadas e expressões de tabela comuns, todas essas outras abordagens que aprendemos ainda são altamente flexíveis e necessárias. Mas, como veremos, operações analíticas comuns geralmente podem ser realizadas com essas funções de janela em vez de ferramentas de subconsulta.\n",
    "\n",
    "Vamos configurar primeiro com o banco de dados `company_operations.db`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75c47be84fdfaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd \n",
    "\n",
    "pd.options.display.max_rows = 999\n",
    "\n",
    "conn = sqlite3.connect('company_operations.db')\n",
    "pd.read_sql(\"SELECT * FROM WEATHER_MONITOR LIMIT 10\", conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62083bada33a8b3",
   "metadata": {},
   "source": [
    "## PARTITION BY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f54155b854e4d9a",
   "metadata": {},
   "source": [
    "Digamos que, em cada registro `WEATHER_MONITOR`, queríamos também mostrar a `TEMPERATURE` média para o `YEAR` e o `MONTH` desse registro. Anteriormente, usávamos uma subconsulta, uma tabela derivada ou uma expressão de tabela comum para isso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbae8fa18b43329",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "WITH temp_avgs AS (\n",
    "    SELECT strftime('%Y', REPORT_DATE) AS YEAR, \n",
    "    strftime('%m', REPORT_DATE) AS MONTH,\n",
    "    AVG(TEMPERATURE) AS AVG_TEMP \n",
    "    FROM WEATHER_MONITOR\n",
    "    GROUP BY 1, 2\n",
    ") \n",
    "\n",
    "SELECT ID, \n",
    "REPORT_CODE, \n",
    "REPORT_DATE, \n",
    "LOCATION_ID, \n",
    "TEMPERATURE, \n",
    "AVG_TEMP\n",
    "\n",
    "FROM WEATHER_MONITOR INNER JOIN temp_avgs\n",
    "\n",
    "ON strftime('%Y', REPORT_DATE) = temp_avgs.YEAR\n",
    "AND strftime('%m', REPORT_DATE) = temp_avgs.MONTH\n",
    "\"\"\"\n",
    "            \n",
    "pd.read_sql(sql, conn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2958d8746d45462",
   "metadata": {},
   "source": [
    "Embora expressões de tabela comuns e subconsultas sejam altamente úteis e personalizáveis, essa tarefa específica é tão comum que existem funções e operadores especiais para ela. Em vez de usar todo esse trabalho de expressão de tabela comum e junção, podemos pegar a temperatura média `AVG(TEMPERATURE)` e `PARTITION` para todos os registros que compartilham o mesmo ano e mês."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dba5ba72b903bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT ID, \n",
    "REPORT_CODE, \n",
    "REPORT_DATE, \n",
    "LOCATION_ID, \n",
    "TEMPERATURE, \n",
    "AVG(TEMPERATURE) OVER (PARTITION BY strftime('%Y', REPORT_DATE), strftime('%m', REPORT_DATE)) AS AVG_TEMP_Y_M\n",
    "\n",
    "FROM WEATHER_MONITOR \n",
    "\n",
    "ORDER BY ID\n",
    "\"\"\"\n",
    "            \n",
    "pd.read_sql(sql, conn, index_col='ID')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5447e44b23f75d",
   "metadata": {},
   "source": [
    "O que é particularmente poderoso em funções de janelamento como `PARTITION BY` é que podemos misturar e combinar diferentes escopos e contextos, com funções de agregação familiares como `MIN`, `MAX`, `AVG`, `SUM` e `COUNT`. Abaixo, adicionamos mais alguns campos analíticos, obtendo as temperaturas média, mínima e máxima para o `LOCATION_ID` de cada registro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cbf5e68e1b66e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT ID, \n",
    "REPORT_CODE, \n",
    "REPORT_DATE, \n",
    "LOCATION_ID, \n",
    "TEMPERATURE, \n",
    "AVG(TEMPERATURE) OVER (PARTITION BY strftime('%Y', REPORT_DATE), strftime('%m', REPORT_DATE)) AS AVG_TEMP_Y_M,\n",
    "AVG(TEMPERATURE) OVER (PARTITION BY LOCATION_ID) AVG_TEMP_LOCATION, \n",
    "MIN(TEMPERATURE) OVER (PARTITION BY LOCATION_ID) MIN_TEMP_LOCATION,\n",
    "MAX(TEMPERATURE) OVER (PARTITION BY LOCATION_ID) MAX_TEMP_LOCATION\n",
    "\n",
    "FROM WEATHER_MONITOR \n",
    "\n",
    "ORDER BY ID\n",
    "\"\"\"\n",
    "            \n",
    "pd.read_sql(sql, conn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ded9ea8ef531908",
   "metadata": {},
   "source": [
    "Também podemos reutilizar cláusulas de janela e criar alias para elas usando a palavra-chave `WINDOW`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf3d1778e8a507a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT ID, \n",
    "REPORT_CODE, \n",
    "REPORT_DATE, \n",
    "LOCATION_ID, \n",
    "TEMPERATURE, \n",
    "AVG(TEMPERATURE) OVER ym AS AVG_TEMP_Y_M,\n",
    "AVG(TEMPERATURE) OVER loc AVG_TEMP_LOCATION, \n",
    "MIN(TEMPERATURE) OVER loc MIN_TEMP_LOCATION,\n",
    "MAX(TEMPERATURE) OVER loc MAX_TEMP_LOCATION\n",
    "\n",
    "FROM WEATHER_MONITOR \n",
    "\n",
    "WINDOW ym AS (PARTITION BY strftime('%Y', REPORT_DATE), strftime('%m', REPORT_DATE)),\n",
    "loc AS (PARTITION BY LOCATION_ID)\n",
    "\n",
    "ORDER BY ID\n",
    "\"\"\"\n",
    "            \n",
    "pd.read_sql(sql, conn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8e94d8a2686105",
   "metadata": {},
   "source": [
    "Lembre-se de que funções de janela como `PARTITION BY` examinarão apenas registros que passarem pela condição `WHERE`. Isso significa que, se você precisar acessar registros que existem fora da condição `WHERE`, precisará voltar a usar subconsultas e expressões de tabela comuns. Observe como a inclusão de uma condição `WHERE` na consulta acima para um único `REPORT_CODE` sufocou todos os outros dados das funções de janela, tornando todos os valores estatísticos `50` em geral, já que agora há apenas um ponto de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996e751eb9615eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT ID, \n",
    "REPORT_CODE, \n",
    "REPORT_DATE, \n",
    "LOCATION_ID, \n",
    "TEMPERATURE, \n",
    "AVG(TEMPERATURE) OVER ym AS AVG_TEMP_Y_M,\n",
    "AVG(TEMPERATURE) OVER loc AVG_TEMP_LOCATION, \n",
    "MIN(TEMPERATURE) OVER loc MIN_TEMP_LOCATION,\n",
    "MAX(TEMPERATURE) OVER loc MAX_TEMP_LOCATION\n",
    "\n",
    "FROM WEATHER_MONITOR \n",
    "WHERE REPORT_CODE = 'UVYMMWW' \n",
    "\n",
    "WINDOW ym AS (PARTITION BY strftime('%Y', REPORT_DATE), strftime('%m', REPORT_DATE)),\n",
    "loc AS (PARTITION BY LOCATION_ID)\n",
    "\"\"\"\n",
    "            \n",
    "pd.read_sql(sql, conn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126ce66c3d10935a",
   "metadata": {},
   "source": [
    "## ORDER BY "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c1ab972fec911f",
   "metadata": {},
   "source": [
    "Aqui está outra aplicação útil de funções de janela. Lembre-se de que podemos usar self joins com condições de join de desigualdade para, por exemplo, obter um total contínuo de pedidos. Supondo que `CUSTOMER_ORDER_ID` reflita a data de entrada cronológica dos pedidos, posso consultar registros anteriores a cada um e somá-los como `ROLLING_QTY`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22effda89c57b6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT c1.CUSTOMER_ORDER_ID, \n",
    "c1.ORDER_DATE,\n",
    "c1.PRODUCT_ID,\n",
    "c1.CUSTOMER_ID,\n",
    "c1.QUANTITY,\n",
    "SUM(c2.QUANTITY) as ROLLING_QTY\n",
    "\n",
    "FROM CUSTOMER_ORDER c1 INNER JOIN CUSTOMER_ORDER c2\n",
    "ON c1.CUSTOMER_ORDER_ID >= c2.CUSTOMER_ORDER_ID\n",
    "\n",
    "GROUP BY 1, 2, 3, 4\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(sql, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b9f62b9f55d1b7",
   "metadata": {},
   "source": [
    "Posso simplificar bastante isso usando uma cláusula `ORDER BY` em uma função analítica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb0007bcf436665",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT CUSTOMER_ORDER_ID, \n",
    "ORDER_DATE,\n",
    "PRODUCT_ID,\n",
    "CUSTOMER_ID,\n",
    "QUANTITY,\n",
    "SUM(QUANTITY) OVER (ORDER BY CUSTOMER_ORDER_ID) as ROLLING_QTY\n",
    "\n",
    "FROM CUSTOMER_ORDER\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(sql, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178709a5c9834d74",
   "metadata": {},
   "source": [
    "Chega de self joins complicadas com a lógica `GROUP BY` estranha! Agora observe que, se usarmos `ORDER BY ORDER_DATE` em vez de `ORDER BY CUSTOMER_ORDER_ID`, algo estranho acontece."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6380d609bd2e1013",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT CUSTOMER_ORDER_ID, \n",
    "ORDER_DATE,\n",
    "PRODUCT_ID,\n",
    "CUSTOMER_ID,\n",
    "QUANTITY,\n",
    "SUM(QUANTITY) OVER (ORDER BY ORDER_DATE) as ROLLING_QTY\n",
    "\n",
    "FROM CUSTOMER_ORDER\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(sql, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce5e71d79c352d2",
   "metadata": {},
   "source": [
    "Cada registro com a mesma `ORDER_DATE` tem a mesma `ROLLING_QTY`. O motivo é que `ORDER_DATE` não possui valores únicos, então cada `ORDER_DATE` soma o total de cada dia. Se quisermos totalizar arbitrariamente linha por linha, é melhor usar um campo único ordenado, como `CUSTOMER_ORDER_ID`. Mas se você ainda quiser fazer o primeiro, use a palavra-chave `ROWS BETWEEN` e especifique o intervalo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad8af50e808b1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT CUSTOMER_ORDER_ID, \n",
    "ORDER_DATE,\n",
    "PRODUCT_ID,\n",
    "CUSTOMER_ID,\n",
    "QUANTITY,\n",
    "SUM(QUANTITY) OVER (ORDER BY ORDER_DATE ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) as ROLLING_QTY\n",
    "FROM CUSTOMER_ORDER\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(sql, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e646f5d40dda718",
   "metadata": {},
   "source": [
    "Tenha cuidado ao usar `ROWS BETWEEN`, pois a ordenação dos registros é arbitrária e alimenta a função, e se você reordenar os registros, obterá resultados confusos. O comportamento padrão `RANGE BETWEEN` geralmente é preferível, pois funciona com valores lógicos em vez de linhas individuais.\n",
    "\n",
    "Também podemos criar médias móveis alterando os limites. Abaixo, criamos uma média móvel entre os 3 registros anteriores e os 3 seguintes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85960d04d66bb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT CUSTOMER_ORDER_ID, \n",
    "ORDER_DATE,\n",
    "PRODUCT_ID,\n",
    "CUSTOMER_ID,\n",
    "QUANTITY,\n",
    "AVG(QUANTITY) OVER (ORDER BY ORDER_DATE ROWS BETWEEN 3 PRECEDING AND 3 FOLLOWING) as ROLLING_AVG\n",
    "FROM CUSTOMER_ORDER\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(sql, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a04dc0780f466f",
   "metadata": {},
   "source": [
    "Vamos voltar a usar a lógica padrão `RANGE BETWEEN`. Se você quiser isolar cada registro para obter o total móvel, mas apenas dentro dos registros que compartilham `PRODUCT_ID` e `CUSTOMER_ID`, adicione `PARTITION BY` novamente. Ao analisar os registros, observe como os totais contínuos contabilizam apenas os registros que compartilham o mesmo `CUSTOMER_ID` e `PRODUCT_ID`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc03065c07fbee7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "sql = \"\"\"\n",
    "SELECT CUSTOMER_ORDER_ID, \n",
    "ORDER_DATE,\n",
    "PRODUCT_ID,\n",
    "CUSTOMER_ID,\n",
    "QUANTITY,\n",
    "SUM(QUANTITY) OVER (PARTITION BY PRODUCT_ID, CUSTOMER_ID ORDER BY ORDER_DATE) as ROLLING_QTY\n",
    "\n",
    "FROM CUSTOMER_ORDER\n",
    "\n",
    "ORDER BY CUSTOMER_ORDER_ID\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(sql, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60676b08efcde580",
   "metadata": {},
   "source": [
    "## LEAD e LAG "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2faaf824df692c52",
   "metadata": {},
   "source": [
    "Duas outras funções de janela muito úteis são `LEAD()` e `LAG()`. Elas permitem recuperar o valor de outro registro com base em um campo ordenado. Abaixo, usamos `LAG()` para procurar o valor do registro anterior. Compare as colunas `QUANTITY` e `PREV_QTY` abaixo e você verá um padrão!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca47d5954afbdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT CUSTOMER_ORDER_ID, \n",
    "CUSTOMER_ID,\n",
    "ORDER_DATE, \n",
    "PRODUCT_ID,\n",
    "QUANTITY,\n",
    "LAG(QUANTITY, 1, 0) OVER (ORDER BY ORDER_DATE) AS PREV_QTY\n",
    "FROM CUSTOMER_ORDER \n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(sql, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db95b84bf9e188ef",
   "metadata": {},
   "source": [
    "A função `LEAD()` procurará o próximo registro à frente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa8380dac84d3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT CUSTOMER_ORDER_ID, \n",
    "CUSTOMER_ID,\n",
    "ORDER_DATE, \n",
    "PRODUCT_ID,\n",
    "QUANTITY,\n",
    "LEAD(QUANTITY, 1, 0) OVER (ORDER BY ORDER_DATE) AS NEXT_QTY\n",
    "FROM CUSTOMER_ORDER \n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(sql, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4216935f4d292d91",
   "metadata": {},
   "source": [
    "Você verá que o segundo e o terceiro argumentos, 1 e 0 nesses casos, controlarão o número de registros a serem procurados à frente/atrás e o valor padrão. Abaixo, alteramos a função `LAG()` para recuperar o terceiro registro atrás dele e definimos o valor padrão para `-1` se não houver nenhum para recuperar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56d9fc279d5e7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT CUSTOMER_ORDER_ID, \n",
    "CUSTOMER_ID,\n",
    "ORDER_DATE, \n",
    "PRODUCT_ID,\n",
    "QUANTITY,\n",
    "LAG(QUANTITY, 3, -1) OVER (ORDER BY ORDER_DATE) AS PREV_QTY\n",
    "FROM CUSTOMER_ORDER \n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(sql, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69b93ec6a5f7b08",
   "metadata": {},
   "source": [
    "## Classificação"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d4bb2331590f3b",
   "metadata": {},
   "source": [
    "A função `ROW_NUMBER()` pode ser muito útil com funções de janela para classificar itens. Por exemplo, digamos que eu queira obter os 3 produtos mais vendidos por cliente. Posso usar `ROW_NUMBER()` para atribuir um número de classificação a cada quantidade classificada por `CUSTOMER_ID` e `PRODUCT_ID`. Assim, posso filtrar apenas os três primeiros itens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4b917bffe1311b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "WITH TOTAL_QTYS AS (\n",
    "  SELECT CUSTOMER_ID, PRODUCT_ID, SUM(QUANTITY) AS TOTAL_QTY \n",
    "  FROM CUSTOMER_ORDER \n",
    "  GROUP BY 1,2\n",
    "),\n",
    "\n",
    "PRODUCT_SALES_BY_CUSTOMER AS (\n",
    "   SELECT CUSTOMER_ID, PRODUCT_ID, TOTAL_QTY,\n",
    "   ROW_NUMBER() OVER (PARTITION BY CUSTOMER_ID ORDER BY TOTAL_QTY DESC) AS RANKING\n",
    "   FROM TOTAL_QTYS\n",
    ") \n",
    "SELECT * FROM PRODUCT_SALES_BY_CUSTOMER \n",
    "WHERE RANKING <= 3\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(sql, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f802bd096eafc6",
   "metadata": {},
   "source": [
    "`RANK()` e `DENSE_RANK()` são idênticos a `ROW_NUMBER()` em comportamento, exceto na forma como valores idênticos são tratados. Se você quiser que valores idênticos recebam a mesma classificação, use a função `RANK()` em vez de `ROW_NUMBER()`. Use `DENSE_RANK()` se quiser forçar os valores a serem consecutivos em vez de duplicatas, fazendo com que as classificações sejam ignoradas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d6df451f71f05f",
   "metadata": {},
   "source": [
    "## Exercício"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6ab956172c7cfb",
   "metadata": {},
   "source": [
    "Para o período de `01/02/2024` a `28/02/2024`, insira a quantidade máxima contínua pedida (até cada `ORDER_DATE`) por `CUSTOMER_ID` e `PRODUCT_ID`. O modelo já está disponível, basta substituir o ponto de interrogação `?` abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992cbf51f622a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT CUSTOMER_ORDER_ID,\n",
    "ORDER_DATE,\n",
    "CUSTOMER_ID,\n",
    "PRODUCT_ID,\n",
    "QUANTITY,\n",
    "? as rolling_max_qty_for_customer_and_product\n",
    "\n",
    "FROM ?\n",
    "WHERE ORDER_DATE BETWEEN '2024-02-01' AND '2024-02-28'\n",
    "\n",
    "ORDER BY CUSTOMER_ORDER_ID\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(sql, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25102e46095e52e",
   "metadata": {},
   "source": [
    "### RESPOSTA A BAIXO\n",
    "\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "|<br>\n",
    "v "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a58732f4ded54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT CUSTOMER_ORDER_ID,\n",
    "ORDER_DATE,\n",
    "CUSTOMER_ID,\n",
    "PRODUCT_ID,\n",
    "QUANTITY,\n",
    "MAX(QUANTITY) OVER(PARTITION BY CUSTOMER_ID, PRODUCT_ID ORDER BY ORDER_DATE) as rolling_max_qty_for_customer_and_product\n",
    "\n",
    "FROM CUSTOMER_ORDER\n",
    "WHERE ORDER_DATE BETWEEN '2024-02-01' AND '2024-02-28'\n",
    "\n",
    "ORDER BY CUSTOMER_ORDER_ID\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(sql, conn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-2024.02-py310",
   "language": "python",
   "name": "conda-env-anaconda-2024.02-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
